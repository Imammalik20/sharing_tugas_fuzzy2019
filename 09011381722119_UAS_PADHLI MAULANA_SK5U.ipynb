{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAMA    : PADHLI MAULANA\n",
    "## NIM        : 09011381722119\n",
    "## KELAS   : SK5U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bank Customer Classification\n",
    "Dataset yang berisi informasi Nasabah Bank, saya akan membuat classifier yang akan memberi tahu  apakah pelanggan akan keluar dari bank atau tidak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah pertama yang kita lakukan adalah mengimport library yang akan kita gunakan.\n",
    "- Library Numpy \n",
    "\n",
    "   berfungsi untuk mengolah data dalam bentuk angka (array)\n",
    "  \n",
    "  \n",
    "- Library Matplotlib \n",
    "\n",
    "   berfungsi untuk membantu visualisasi dataset sehingga memudahkan untuk dipahami\n",
    "  \n",
    "  \n",
    "- Library Theano\n",
    "\n",
    "  Theano adalah pustaka Python dan mengoptimalkan kompiler untuk memanipulasi dan mengevaluasi ekspresi matematika, terutama   yang bernilai matriks.\n",
    "  \n",
    "  \n",
    "- Library Pandas\n",
    "\n",
    "  Berfungsi untuk membaca file dataset dalam bentuk .CSV\n",
    "  \n",
    "  \n",
    "- Library Tensorflow\n",
    "\n",
    "  tensorflow adalah tools untuk melakukan komputasi numerik (lebih luas daripada hanya sekedar untuk deep learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "#### Dataset tersebut memiliki 13 anggota dengan 1 parameter Output\n",
    "1. Rownumber\n",
    "2. Customerld (Pelanggan)\n",
    "3. Surename (Nama Pelanggan)\n",
    "4. CreditScore\n",
    "5. Geography (letak negara)\n",
    "6. Gender (Laki-Laki,Perempuan)\n",
    "7. Age (umur)\n",
    "8. Tenure\n",
    "9. Balance\n",
    "10. NumOfProducts\n",
    "11. HasCrCard\n",
    "12. IsActiveNumber\n",
    "13. EstimatedSalary\n",
    "14. Exited (OUTPUT) -> (1 = Keluar dari bank, 0 = tidak keluar dari bank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam dataset ini, saya harus mempertimbangkan faktor mana yang mungkin berperan dalam seseorang yang keluar dari bank. Untuk melakukan itu saya harus melihat semua kolom dan menyimpulkan apakah penting untuk mengklasifikasikan pelanggan baru atau tidak. Informasi tentang pelanggan disyaratkan dalam kolom 1 hingga 13 (RowNumber-EstimatedSalary), sedangkan output (apakah pelanggan keluar atau tidak) disimpan di baris ke-14 (Keluar) .\n",
    "\n",
    "Selama kita peduli, baik ID pelanggan, maupun nama keluarga tidak boleh penting dalam klasifikasi. Karena itu, kami akan menggunakan kolom 3 (CreditScore) inklusif melalui kolom ke-13 (eksklusif).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari dataset diatas bdapat di lihat bahwa data berisi 10.000 baris dan 14 kolom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengecek apakah ada data kosong\n",
    "Setelah kita menimport dataset ada baiknya kita terlebih dahulu melakukan pegecekaan terhadap dataset kita, apakah data tersebih sudah bersih atau masih ada data kosong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menentukan Features dan Labels\n",
    "features dimulai dari kolom 4 - 13 sedangkan untuk Lables sendiri kita ambil pada kolom terakhir yakni kolom 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,3:13].values # Credit Score through Estimated Salary\n",
    "y = dataset.iloc[:, 13].values # Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France' 'Spain' 'France' 'France' 'Spain' 'Spain' 'France' 'Germany'] ... will now become: \n",
      "[0 2 0 0 2 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical (string based) data. Country: there are 3 options: France, Spain and Germany\n",
    "# This will convert those strings into scalar values for analysis\n",
    "print(X[:8,1], '... will now become: ')\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_X_country_encoder = LabelEncoder()\n",
    "X[:,1] = label_X_country_encoder.fit_transform(X[:,1])\n",
    "print(X[:8,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masalahnya di sini adalah bahwa kita memperlakukan negara sebagai satu variabel dengan nilai ordinal (0 <1 <2). Oleh karena itu, salah satu cara untuk menyingkirkan masalah itu adalah dengan membagi negara-negara ke dalam dimensi masing-masing. itu adalah :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Country</th>\n",
    "        <th>--></th>\n",
    "        <th>Country</th>\n",
    "        <th>--></th>\n",
    "        <th>France</th>\n",
    "        <th>Germany</th>\n",
    "        <th>Spain</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>France</td>\n",
    "        <td>--></td>\n",
    "        <td>0</td>\n",
    "        <td>--></td>\n",
    "        <td>1</td>\n",
    "        <td>0</td>\n",
    "        <td>0</td>  \n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td>Germany</td>\n",
    "        <td>--></td>\n",
    "        <td>1</td>\n",
    "        <td>--></td>\n",
    "        <td>0</td>\n",
    "        <td>1</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td>Spain</td>\n",
    "        <td>--></td>\n",
    "        <td>2</td>\n",
    "        <td>--></td>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female' 'Female' 'Female' 'Female' 'Female' 'Male'] ... will now become: \n",
      "[0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# We will do the same thing for gender. this will be binary in this dataset\n",
    "print(X[:6,2], '... will now become: ')\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_X_gender_encoder = LabelEncoder()\n",
    "X[:,2] = label_X_gender_encoder.fit_transform(X[:,2])\n",
    "print(X[:6,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender tidak perlu melalui proses yang sama karena ini adalah biner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Converting the string features into their own dimensions. Gender doesn't matter here because its binary\n",
    "countryhotencoder = OneHotEncoder(categorical_features = [1]) # 1 is the country column\n",
    "X = countryhotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0134888e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 1.1254258e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
       "        0.0000000e+00, 1.1393157e+05],\n",
       "       ...,\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 4.2085580e+04],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
       "        0.0000000e+00, 9.2888520e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
       "        0.0000000e+00, 3.8190780e+04]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sekarang kita dapat melihat bahwa tiga kolom pertama mewakili tiga negara yang membentuk kategori \"negara\". Kita sekarang dapat mengamati bahwa pada dasarnya kita hanya membutuhkan dua kolom: a 0 pada dua negara berarti bahwa negara tersebut harus menjadi satu variabel yang tidak termasuk. Ini akan menyelamatkan kita dari masalah menggunakan terlalu banyak dimensi.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>France</th>\n",
    "        <th>Germany</th>\n",
    "        <th>Spain</th>\n",
    "        <th>--></th>\n",
    "        <th>Germany</th>\n",
    "        <th>Spain</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "        <td>--></td>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td>0</td>\n",
    "        <td>1</td>\n",
    "        <td>0</td>\n",
    "        <td>--></td>\n",
    "         <td>1</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "        <td>1</td>\n",
    "        <td>--></td>\n",
    "         <td>0</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,1:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menyingkirkan France sebagai dimensi. Itu masih ada melalui kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dan Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training and Testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penskalaan fitur adalah metode yang digunakan untuk menstandarisasi berbagai variabel independen atau fitur data. Ini pada dasarnya skala semua dimensi menjadi bahkan sehingga satu variabel independen tidak mendominasi yang lain. Misalnya, saldo rekening bank berkisar dari jutaan hingga 0, sedangkan jenis kelaminnya 0 atau 1. Jika salah satu fitur memiliki rentang nilai yang luas, jarak akan diatur oleh fitur khusus ini. Oleh karena itu, rentang semua fitur harus dinormalisasi sehingga setiap fitur berkontribusi sekitar secara proporsional terhadap jarak akhir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5698444 ,  1.74309049,  0.16958176, ...,  0.64259497,\n",
       "        -1.03227043,  1.10643166],\n",
       "       [ 1.75486502, -0.57369368, -2.30455945, ...,  0.64259497,\n",
       "         0.9687384 , -0.74866447],\n",
       "       [-0.5698444 , -0.57369368, -1.19119591, ...,  0.64259497,\n",
       "        -1.03227043,  1.48533467],\n",
       "       ...,\n",
       "       [-0.5698444 , -0.57369368,  0.9015152 , ...,  0.64259497,\n",
       "        -1.03227043,  1.41231994],\n",
       "       [-0.5698444 ,  1.74309049, -0.62420521, ...,  0.64259497,\n",
       "         0.9687384 ,  0.84432121],\n",
       "       [ 1.75486502, -0.57369368, -0.28401079, ...,  0.64259497,\n",
       "        -1.03227043,  0.32472465]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebuah ujung yang berbahaya adalah bahwa jumlah node (dimensi) di lapisan tersembunyi Anda harus menjadi rata-rata dari layer input dan output Anda, yang berarti bahwa karena kami memiliki 11 dimensi (mewakili variabel independen Catatan: Negara-negara masih menyusun hanya satu dimensi) dan kami sedang mencari keluaran biner, kami menghitung ini menjadi (11 + 1) ÷ 2 = 6\n",
    "\n",
    ".\n",
    "Rincian input untuk lapisan pertama adalah sebagai berikut:\n",
    "\n",
    "activiation: relu karena kita berada di lapisan input. menggunakan fungsi aktivasi ReLu untuk ϕ\n",
    "\n",
    "input_dim: 11 karena kami menjangkau 11 dimensi di lapisan input kami. Ini diperlukan untuk lapisan tambahan pertama. Dimensi input layer selanjutnya dapat disimpulkan menggunakan dimensi output layer yang ditambahkan sebelumnya. Lapisan tersembunyi berikutnya akan tahu apa yang diharapkan.\n",
    "\n",
    "unit: 6 node (jumlah node di lapisan tersembunyi). Dapat menganggap ini sebagai jumlah node di lapisan berikutnya.\n",
    "\n",
    "kernel_initializer: seragam distribusi dengan mana kita secara acak menginisialisasi bobot untuk node di lapisan ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n",
    "classifier.add(Dense(activation = 'relu', input_dim = 11, units=6, kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saya akan menambahkan lapisan lain ke model ini karena saya ingin menerapkan Deep Learning, yang merupakan jaringan saraf tiruan dengan banyak lapisan.\n",
    "\n",
    "Kami akan membuat layer tersembunyi kedua kami juga memiliki 6 node, hanya bermain dengan aritmatika yang sama yang kami gunakan untuk menentukan dimensi dari layer tersembunyi pertama (rata-rata layer input dan output Anda) (11 + 1) ÷ 2 = 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "# Notice that we do not need to specify input dim. \n",
    "classifier.add(Dense(activation = 'relu', units=6, kernel_initializer='uniform')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menambahkan lapisan output\n",
    "Rincian input untuk lapisan keluaran adalah sebagai berikut:\n",
    "\n",
    "- activiation: sigmoid karena kita berada dalam lapisan output. menggunakan fungsi aktivasi Sigmoid untuk Ini digunakan sebagai ganti fungsi ReLu karena ia menghasilkan probabilitas untuk hasilnya. Kami ingin probabilitas bahwa setiap pelanggan meninggalkan bank.\n",
    "\n",
    "\n",
    "- input_dim: 11 karena kami menjangkau 11 dimensi di lapisan input kami. Ini diperlukan untuk lapisan tambahan pertama. Dimensi input layer selanjutnya dapat disimpulkan menggunakan dimensi output layer yang ditambahkan sebelumnya. Lapisan tersembunyi berikutnya akan tahu apa yang diharapkan.\n",
    "\n",
    "\n",
    "- unit: 6 node (jumlah node di lapisan tersembunyi). Dapat menganggap ini sebagai jumlah node di lapisan berikutnya.\n",
    "\n",
    "\n",
    "- kernel_initializer: seragam distribusi dengan mana kita secara acak menginisialisasi bobot untuk node di lapisan ini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "# Notice that we do not need to specify input dim. \n",
    "# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n",
    "# We use the sigmoid because we want probability outcomes\n",
    "classifier.add(Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika ingin lebih dari dua kategori, maka kita perlu berubah\n",
    "\n",
    "1) parameter unit agar sesuai dengan jumlah kategori yang diinginkan\n",
    "\n",
    "2) bidang aktivasi ke softmax. Pada dasarnya fungsi sigmoid tetapi diterapkan pada variabel dependen yang memiliki lebih dari 2 kategori.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada dasarnya menerapkan keturunan Gradien Stochastic pada seluruh Jaringan Saraf Tiruan. Kami menyetel bobot individu pada setiap neuron.\n",
    "Rincian input untuk kompilasi adalah sebagai berikut:\n",
    "\n",
    "- optimizer: adam Algoritma yang ingin kita gunakan untuk menemukan set bobot optimal dalam jaringan saraf. Adam adalah variasi yang sangat efektif dari Stochastic Gradient Descent.\n",
    "\n",
    "\n",
    "- loss: binary_crossentropy Ini adalah fungsi loss yang digunakan dalam adam. Ini harus menjadi kerugian logarthmic. Jika dependen kami (variabel output) adalah Biner, itu adalah binary_crossentropy. Jika Kategorikal, maka itu disebut kategorikal_crossentropi\n",
    "\n",
    "\n",
    "- metrik: [akurasi] Metrik akurasi yang akan dievaluasi (diminimalkan) oleh model. Digunakan sebagai kriteria akurasi untuk meningkatkan kinerja model.\n",
    "\n",
    "\n",
    "- kernel_initializer: seragam distribusi dengan mana kita secara acak menginisialisasi bobot untuk node di lapisan ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di sinilah saya akan menyesuaikan JST ke set training.\n",
    "Rincian input untuk kompilasi adalah sebagai berikut:\n",
    "\n",
    "- X_train Bagian variabel independen dari data yang perlu dipasangkan dengan model.\n",
    "\n",
    "- Y_train Bagian output dari data yang model perlu hasilkan setelah pemasangan.\n",
    "\n",
    "- batch_size: Seberapa sering kita ingin melakukan back-propogate nilai kesalahan sehingga bobot masing-masing simpul dapat disesuaikan.\n",
    "\n",
    "- nb_epochs: Frekuensi kami ingin menjalankan seluruh data pengujian lagi untuk menyesuaikan bobotnya. Ini seperti bahan bakar dari algoritma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.6605 - accuracy: 0.7929 - val_loss: 0.6306 - val_accuracy: 0.7975\n",
      "Epoch 2/200\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 0.6077 - accuracy: 0.7960 - val_loss: 0.5864 - val_accuracy: 0.7975\n",
      "Epoch 3/200\n",
      "8000/8000 [==============================] - 2s 196us/step - loss: 0.5336 - accuracy: 0.8010 - val_loss: 0.4261 - val_accuracy: 0.8345\n",
      "Epoch 4/200\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.4141 - accuracy: 0.8264 - val_loss: 0.4024 - val_accuracy: 0.8390\n",
      "Epoch 5/200\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 0.4071 - accuracy: 0.8310 - val_loss: 0.3983 - val_accuracy: 0.8365\n",
      "Epoch 6/200\n",
      "8000/8000 [==============================] - 1s 179us/step - loss: 0.4027 - accuracy: 0.8309 - val_loss: 0.3936 - val_accuracy: 0.8380\n",
      "Epoch 7/200\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 0.3975 - accuracy: 0.8321 - val_loss: 0.3904 - val_accuracy: 0.8340\n",
      "Epoch 8/200\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 0.3925 - accuracy: 0.8332 - val_loss: 0.3867 - val_accuracy: 0.8355\n",
      "Epoch 9/200\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.3884 - accuracy: 0.8331 - val_loss: 0.3813 - val_accuracy: 0.8390\n",
      "Epoch 10/200\n",
      "8000/8000 [==============================] - 3s 316us/step - loss: 0.3846 - accuracy: 0.8353 - val_loss: 0.3791 - val_accuracy: 0.8305\n",
      "Epoch 11/200\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 0.3818 - accuracy: 0.8351 - val_loss: 0.3755 - val_accuracy: 0.8360\n",
      "Epoch 12/200\n",
      "8000/8000 [==============================] - 1s 160us/step - loss: 0.3789 - accuracy: 0.8344 - val_loss: 0.3728 - val_accuracy: 0.8355\n",
      "Epoch 13/200\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.3763 - accuracy: 0.8344 - val_loss: 0.3716 - val_accuracy: 0.8365\n",
      "Epoch 14/200\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.3744 - accuracy: 0.8338 - val_loss: 0.3684 - val_accuracy: 0.8385\n",
      "Epoch 15/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3719 - accuracy: 0.8370 - val_loss: 0.3652 - val_accuracy: 0.8375\n",
      "Epoch 16/200\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 0.3700 - accuracy: 0.8432 - val_loss: 0.3629 - val_accuracy: 0.8490\n",
      "Epoch 17/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 0.3681 - accuracy: 0.8471 - val_loss: 0.3641 - val_accuracy: 0.8470\n",
      "Epoch 18/200\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.3662 - accuracy: 0.8521 - val_loss: 0.3596 - val_accuracy: 0.8515\n",
      "Epoch 19/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 0.3648 - accuracy: 0.8499 - val_loss: 0.3570 - val_accuracy: 0.8520\n",
      "Epoch 20/200\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 0.3629 - accuracy: 0.8516 - val_loss: 0.3571 - val_accuracy: 0.8540\n",
      "Epoch 21/200\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 0.3617 - accuracy: 0.8535 - val_loss: 0.3549 - val_accuracy: 0.8535\n",
      "Epoch 22/200\n",
      "8000/8000 [==============================] - 2s 199us/step - loss: 0.3601 - accuracy: 0.8529 - val_loss: 0.3529 - val_accuracy: 0.8520\n",
      "Epoch 23/200\n",
      "8000/8000 [==============================] - 2s 203us/step - loss: 0.3590 - accuracy: 0.8541 - val_loss: 0.3532 - val_accuracy: 0.8545\n",
      "Epoch 24/200\n",
      "8000/8000 [==============================] - 2s 192us/step - loss: 0.3573 - accuracy: 0.8545 - val_loss: 0.3506 - val_accuracy: 0.8545\n",
      "Epoch 25/200\n",
      "8000/8000 [==============================] - 3s 356us/step - loss: 0.3565 - accuracy: 0.8543 - val_loss: 0.3491 - val_accuracy: 0.8530\n",
      "Epoch 26/200\n",
      "8000/8000 [==============================] - 1s 157us/step - loss: 0.3559 - accuracy: 0.8543 - val_loss: 0.3502 - val_accuracy: 0.8565\n",
      "Epoch 27/200\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.3546 - accuracy: 0.8562 - val_loss: 0.3479 - val_accuracy: 0.8585\n",
      "Epoch 28/200\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 0.3539 - accuracy: 0.8558 - val_loss: 0.3515 - val_accuracy: 0.8545\n",
      "Epoch 29/200\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 0.3533 - accuracy: 0.8553 - val_loss: 0.3448 - val_accuracy: 0.8565\n",
      "Epoch 30/200\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 0.3525 - accuracy: 0.8561 - val_loss: 0.3472 - val_accuracy: 0.8585\n",
      "Epoch 31/200\n",
      "8000/8000 [==============================] - 1s 168us/step - loss: 0.3518 - accuracy: 0.8561 - val_loss: 0.3463 - val_accuracy: 0.8555\n",
      "Epoch 32/200\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.3514 - accuracy: 0.8565 - val_loss: 0.3464 - val_accuracy: 0.8545\n",
      "Epoch 33/200\n",
      "8000/8000 [==============================] - 1s 168us/step - loss: 0.3506 - accuracy: 0.8581 - val_loss: 0.3439 - val_accuracy: 0.8540\n",
      "Epoch 34/200\n",
      "8000/8000 [==============================] - 1s 180us/step - loss: 0.3505 - accuracy: 0.8576 - val_loss: 0.3482 - val_accuracy: 0.8570\n",
      "Epoch 35/200\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 0.3499 - accuracy: 0.8569 - val_loss: 0.3440 - val_accuracy: 0.8600\n",
      "Epoch 36/200\n",
      "8000/8000 [==============================] - 1s 186us/step - loss: 0.3489 - accuracy: 0.8571 - val_loss: 0.3422 - val_accuracy: 0.8560\n",
      "Epoch 37/200\n",
      "8000/8000 [==============================] - 2s 245us/step - loss: 0.3492 - accuracy: 0.8560 - val_loss: 0.3417 - val_accuracy: 0.8545\n",
      "Epoch 38/200\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 0.3483 - accuracy: 0.8587 - val_loss: 0.3418 - val_accuracy: 0.8540\n",
      "Epoch 39/200\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.3479 - accuracy: 0.8569 - val_loss: 0.3428 - val_accuracy: 0.8550\n",
      "Epoch 40/200\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 0.3476 - accuracy: 0.8587 - val_loss: 0.3416 - val_accuracy: 0.8545\n",
      "Epoch 41/200\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.3471 - accuracy: 0.8575 - val_loss: 0.3439 - val_accuracy: 0.8535\n",
      "Epoch 42/200\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 0.3472 - accuracy: 0.8577 - val_loss: 0.3417 - val_accuracy: 0.8550\n",
      "Epoch 43/200\n",
      "8000/8000 [==============================] - 2s 198us/step - loss: 0.3467 - accuracy: 0.8568 - val_loss: 0.3444 - val_accuracy: 0.8540\n",
      "Epoch 44/200\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.3461 - accuracy: 0.8579 - val_loss: 0.3422 - val_accuracy: 0.8505\n",
      "Epoch 45/200\n",
      "8000/8000 [==============================] - 1s 174us/step - loss: 0.3460 - accuracy: 0.8576 - val_loss: 0.3390 - val_accuracy: 0.8575\n",
      "Epoch 46/200\n",
      "8000/8000 [==============================] - 3s 386us/step - loss: 0.3455 - accuracy: 0.8585 - val_loss: 0.3378 - val_accuracy: 0.8555\n",
      "Epoch 47/200\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.3448 - accuracy: 0.8575 - val_loss: 0.3375 - val_accuracy: 0.8545\n",
      "Epoch 48/200\n",
      "8000/8000 [==============================] - 1s 184us/step - loss: 0.3450 - accuracy: 0.8587 - val_loss: 0.3377 - val_accuracy: 0.8585\n",
      "Epoch 49/200\n",
      "8000/8000 [==============================] - 3s 352us/step - loss: 0.3443 - accuracy: 0.8591 - val_loss: 0.3389 - val_accuracy: 0.8580\n",
      "Epoch 50/200\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 0.3439 - accuracy: 0.8586 - val_loss: 0.3396 - val_accuracy: 0.8545\n",
      "Epoch 51/200\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.3432 - accuracy: 0.8593 - val_loss: 0.3385 - val_accuracy: 0.8560\n",
      "Epoch 52/200\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.3433 - accuracy: 0.8584 - val_loss: 0.3401 - val_accuracy: 0.8520\n",
      "Epoch 53/200\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 0.3426 - accuracy: 0.8589 - val_loss: 0.3360 - val_accuracy: 0.8595\n",
      "Epoch 54/200\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 0.3416 - accuracy: 0.8599 - val_loss: 0.3371 - val_accuracy: 0.8575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3427 - accuracy: 0.8585 - val_loss: 0.3383 - val_accuracy: 0.8550\n",
      "Epoch 56/200\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.3419 - accuracy: 0.8586 - val_loss: 0.3385 - val_accuracy: 0.8550\n",
      "Epoch 57/200\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.3419 - accuracy: 0.8589 - val_loss: 0.3367 - val_accuracy: 0.8540\n",
      "Epoch 58/200\n",
      "8000/8000 [==============================] - 1s 164us/step - loss: 0.3413 - accuracy: 0.8596 - val_loss: 0.3396 - val_accuracy: 0.8520\n",
      "Epoch 59/200\n",
      "8000/8000 [==============================] - 2s 245us/step - loss: 0.3417 - accuracy: 0.8601 - val_loss: 0.3431 - val_accuracy: 0.8525\n",
      "Epoch 60/200\n",
      "8000/8000 [==============================] - 1s 154us/step - loss: 0.3416 - accuracy: 0.8585 - val_loss: 0.3374 - val_accuracy: 0.8540\n",
      "Epoch 61/200\n",
      "8000/8000 [==============================] - 1s 179us/step - loss: 0.3413 - accuracy: 0.8577 - val_loss: 0.3411 - val_accuracy: 0.8545\n",
      "Epoch 62/200\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 0.3407 - accuracy: 0.8618 - val_loss: 0.3425 - val_accuracy: 0.8540\n",
      "Epoch 63/200\n",
      "8000/8000 [==============================] - 2s 195us/step - loss: 0.3401 - accuracy: 0.8602 - val_loss: 0.3445 - val_accuracy: 0.8505\n",
      "Epoch 64/200\n",
      "8000/8000 [==============================] - 2s 189us/step - loss: 0.3402 - accuracy: 0.8587 - val_loss: 0.3403 - val_accuracy: 0.8555\n",
      "Epoch 65/200\n",
      "8000/8000 [==============================] - 1s 172us/step - loss: 0.3400 - accuracy: 0.8600 - val_loss: 0.3379 - val_accuracy: 0.8570\n",
      "Epoch 66/200\n",
      "8000/8000 [==============================] - 2s 191us/step - loss: 0.3400 - accuracy: 0.8591 - val_loss: 0.3420 - val_accuracy: 0.8525\n",
      "Epoch 67/200\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 0.3397 - accuracy: 0.8609 - val_loss: 0.3353 - val_accuracy: 0.8560\n",
      "Epoch 68/200\n",
      "8000/8000 [==============================] - 1s 169us/step - loss: 0.3397 - accuracy: 0.8595 - val_loss: 0.3362 - val_accuracy: 0.8560\n",
      "Epoch 69/200\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.3397 - accuracy: 0.8593 - val_loss: 0.3406 - val_accuracy: 0.8540\n",
      "Epoch 70/200\n",
      "8000/8000 [==============================] - 2s 246us/step - loss: 0.3395 - accuracy: 0.8583 - val_loss: 0.3382 - val_accuracy: 0.8560\n",
      "Epoch 71/200\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 0.3391 - accuracy: 0.8579 - val_loss: 0.3364 - val_accuracy: 0.8595\n",
      "Epoch 72/200\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 0.3392 - accuracy: 0.8583 - val_loss: 0.3371 - val_accuracy: 0.8565\n",
      "Epoch 73/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 0.3388 - accuracy: 0.8605 - val_loss: 0.3361 - val_accuracy: 0.8575\n",
      "Epoch 74/200\n",
      "8000/8000 [==============================] - 1s 131us/step - loss: 0.3391 - accuracy: 0.8599 - val_loss: 0.3379 - val_accuracy: 0.8545\n",
      "Epoch 75/200\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.3394 - accuracy: 0.8610 - val_loss: 0.3372 - val_accuracy: 0.8550\n",
      "Epoch 76/200\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.3384 - accuracy: 0.8602 - val_loss: 0.3383 - val_accuracy: 0.8530\n",
      "Epoch 77/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.3389 - accuracy: 0.8602 - val_loss: 0.3369 - val_accuracy: 0.8565\n",
      "Epoch 78/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3388 - accuracy: 0.8600 - val_loss: 0.3426 - val_accuracy: 0.8510\n",
      "Epoch 79/200\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.3387 - accuracy: 0.8608 - val_loss: 0.3398 - val_accuracy: 0.8545\n",
      "Epoch 80/200\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 0.3388 - accuracy: 0.8586 - val_loss: 0.3362 - val_accuracy: 0.8570\n",
      "Epoch 81/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.3387 - accuracy: 0.8620 - val_loss: 0.3371 - val_accuracy: 0.8565\n",
      "Epoch 82/200\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 0.3384 - accuracy: 0.8609 - val_loss: 0.3373 - val_accuracy: 0.8565\n",
      "Epoch 83/200\n",
      "8000/8000 [==============================] - 2s 250us/step - loss: 0.3382 - accuracy: 0.8611 - val_loss: 0.3369 - val_accuracy: 0.8585\n",
      "Epoch 84/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3383 - accuracy: 0.8599 - val_loss: 0.3359 - val_accuracy: 0.8575\n",
      "Epoch 85/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3384 - accuracy: 0.8594 - val_loss: 0.3363 - val_accuracy: 0.8580\n",
      "Epoch 86/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3383 - accuracy: 0.8580 - val_loss: 0.3383 - val_accuracy: 0.8580\n",
      "Epoch 87/200\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 0.3380 - accuracy: 0.8614 - val_loss: 0.3373 - val_accuracy: 0.8530\n",
      "Epoch 88/200\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.3379 - accuracy: 0.8585 - val_loss: 0.3421 - val_accuracy: 0.8555\n",
      "Epoch 89/200\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 0.3379 - accuracy: 0.8595 - val_loss: 0.3413 - val_accuracy: 0.8575\n",
      "Epoch 90/200\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 0.3388 - accuracy: 0.8605 - val_loss: 0.3395 - val_accuracy: 0.8560\n",
      "Epoch 91/200\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 0.3379 - accuracy: 0.8599 - val_loss: 0.3362 - val_accuracy: 0.8585\n",
      "Epoch 92/200\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.3378 - accuracy: 0.8596 - val_loss: 0.3385 - val_accuracy: 0.8570\n",
      "Epoch 93/200\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.3379 - accuracy: 0.8605 - val_loss: 0.3383 - val_accuracy: 0.8585\n",
      "Epoch 94/200\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 0.3378 - accuracy: 0.8610 - val_loss: 0.3380 - val_accuracy: 0.8545\n",
      "Epoch 95/200\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 0.3377 - accuracy: 0.8616 - val_loss: 0.3411 - val_accuracy: 0.8575\n",
      "Epoch 96/200\n",
      "8000/8000 [==============================] - 4s 456us/step - loss: 0.3379 - accuracy: 0.8596 - val_loss: 0.3376 - val_accuracy: 0.8580\n",
      "Epoch 97/200\n",
      "8000/8000 [==============================] - 1s 157us/step - loss: 0.3376 - accuracy: 0.8594 - val_loss: 0.3400 - val_accuracy: 0.8550\n",
      "Epoch 98/200\n",
      "8000/8000 [==============================] - 1s 158us/step - loss: 0.3373 - accuracy: 0.8611 - val_loss: 0.3418 - val_accuracy: 0.8555\n",
      "Epoch 99/200\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 0.3378 - accuracy: 0.8615 - val_loss: 0.3375 - val_accuracy: 0.8595\n",
      "Epoch 100/200\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 0.3376 - accuracy: 0.8587 - val_loss: 0.3372 - val_accuracy: 0.8580\n",
      "Epoch 101/200\n",
      "8000/8000 [==============================] - 1s 181us/step - loss: 0.3371 - accuracy: 0.8594 - val_loss: 0.3385 - val_accuracy: 0.8590\n",
      "Epoch 102/200\n",
      "8000/8000 [==============================] - 1s 170us/step - loss: 0.3368 - accuracy: 0.8616 - val_loss: 0.3404 - val_accuracy: 0.8545\n",
      "Epoch 103/200\n",
      "8000/8000 [==============================] - 2s 198us/step - loss: 0.3373 - accuracy: 0.8609 - val_loss: 0.3360 - val_accuracy: 0.8620\n",
      "Epoch 104/200\n",
      "8000/8000 [==============================] - 2s 189us/step - loss: 0.3376 - accuracy: 0.8602 - val_loss: 0.3341 - val_accuracy: 0.8610\n",
      "Epoch 105/200\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.3365 - accuracy: 0.8606 - val_loss: 0.3376 - val_accuracy: 0.8580\n",
      "Epoch 106/200\n",
      "8000/8000 [==============================] - 2s 298us/step - loss: 0.3370 - accuracy: 0.8591 - val_loss: 0.3376 - val_accuracy: 0.8580\n",
      "Epoch 107/200\n",
      "8000/8000 [==============================] - 1s 175us/step - loss: 0.3364 - accuracy: 0.8610 - val_loss: 0.3373 - val_accuracy: 0.8590\n",
      "Epoch 108/200\n",
      "8000/8000 [==============================] - 1s 173us/step - loss: 0.3369 - accuracy: 0.8608 - val_loss: 0.3375 - val_accuracy: 0.8615\n",
      "Epoch 109/200\n",
      "8000/8000 [==============================] - 1s 180us/step - loss: 0.3373 - accuracy: 0.8616 - val_loss: 0.3376 - val_accuracy: 0.8565\n",
      "Epoch 110/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 0.3369 - accuracy: 0.8605 - val_loss: 0.3417 - val_accuracy: 0.8580\n",
      "Epoch 111/200\n",
      "8000/8000 [==============================] - 1s 132us/step - loss: 0.3371 - accuracy: 0.8611 - val_loss: 0.3375 - val_accuracy: 0.8595\n",
      "Epoch 112/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3371 - accuracy: 0.8619 - val_loss: 0.3391 - val_accuracy: 0.8595\n",
      "Epoch 113/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3372 - accuracy: 0.8612 - val_loss: 0.3390 - val_accuracy: 0.8580\n",
      "Epoch 114/200\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 0.3366 - accuracy: 0.8591 - val_loss: 0.3458 - val_accuracy: 0.8545\n",
      "Epoch 115/200\n",
      "8000/8000 [==============================] - 1s 179us/step - loss: 0.3375 - accuracy: 0.8600 - val_loss: 0.3374 - val_accuracy: 0.8605\n",
      "Epoch 116/200\n",
      "8000/8000 [==============================] - 1s 180us/step - loss: 0.3366 - accuracy: 0.8594 - val_loss: 0.3370 - val_accuracy: 0.8640\n",
      "Epoch 117/200\n",
      "8000/8000 [==============================] - 3s 321us/step - loss: 0.3372 - accuracy: 0.8618 - val_loss: 0.3420 - val_accuracy: 0.8555\n",
      "Epoch 118/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.3367 - accuracy: 0.8600 - val_loss: 0.3380 - val_accuracy: 0.8570\n",
      "Epoch 119/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.3366 - accuracy: 0.8616 - val_loss: 0.3392 - val_accuracy: 0.8575\n",
      "Epoch 120/200\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.3369 - accuracy: 0.8614 - val_loss: 0.3376 - val_accuracy: 0.8590\n",
      "Epoch 121/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3368 - accuracy: 0.8602 - val_loss: 0.3414 - val_accuracy: 0.8525\n",
      "Epoch 122/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3369 - accuracy: 0.8611 - val_loss: 0.3357 - val_accuracy: 0.8640\n",
      "Epoch 123/200\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.3363 - accuracy: 0.8612 - val_loss: 0.3377 - val_accuracy: 0.8560\n",
      "Epoch 124/200\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 0.3365 - accuracy: 0.8596 - val_loss: 0.3362 - val_accuracy: 0.8615\n",
      "Epoch 125/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3372 - accuracy: 0.8601 - val_loss: 0.3376 - val_accuracy: 0.8615\n",
      "Epoch 126/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.3363 - accuracy: 0.8605 - val_loss: 0.3391 - val_accuracy: 0.8610\n",
      "Epoch 127/200\n",
      "8000/8000 [==============================] - 1s 164us/step - loss: 0.3367 - accuracy: 0.8600 - val_loss: 0.3368 - val_accuracy: 0.8600\n",
      "Epoch 128/200\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 0.3366 - accuracy: 0.8611 - val_loss: 0.3385 - val_accuracy: 0.8610\n",
      "Epoch 129/200\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 0.3365 - accuracy: 0.8605 - val_loss: 0.3365 - val_accuracy: 0.8605\n",
      "Epoch 130/200\n",
      "8000/8000 [==============================] - 2s 291us/step - loss: 0.3367 - accuracy: 0.8611 - val_loss: 0.3411 - val_accuracy: 0.8590\n",
      "Epoch 131/200\n",
      "8000/8000 [==============================] - 1s 160us/step - loss: 0.3369 - accuracy: 0.8601 - val_loss: 0.3391 - val_accuracy: 0.8575\n",
      "Epoch 132/200\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 0.3368 - accuracy: 0.8597 - val_loss: 0.3347 - val_accuracy: 0.8605\n",
      "Epoch 133/200\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 0.3374 - accuracy: 0.8599 - val_loss: 0.3386 - val_accuracy: 0.8575\n",
      "Epoch 134/200\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 0.3364 - accuracy: 0.8616 - val_loss: 0.3409 - val_accuracy: 0.8565\n",
      "Epoch 135/200\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 0.3369 - accuracy: 0.8610 - val_loss: 0.3380 - val_accuracy: 0.8565\n",
      "Epoch 136/200\n",
      "8000/8000 [==============================] - 1s 157us/step - loss: 0.3365 - accuracy: 0.8622 - val_loss: 0.3382 - val_accuracy: 0.8590\n",
      "Epoch 137/200\n",
      "8000/8000 [==============================] - 1s 179us/step - loss: 0.3364 - accuracy: 0.8595 - val_loss: 0.3362 - val_accuracy: 0.8600\n",
      "Epoch 138/200\n",
      "8000/8000 [==============================] - 2s 196us/step - loss: 0.3364 - accuracy: 0.8624 - val_loss: 0.3378 - val_accuracy: 0.8620\n",
      "Epoch 139/200\n",
      "8000/8000 [==============================] - 3s 367us/step - loss: 0.3363 - accuracy: 0.8629 - val_loss: 0.3415 - val_accuracy: 0.8570\n",
      "Epoch 140/200\n",
      "8000/8000 [==============================] - 2s 257us/step - loss: 0.3363 - accuracy: 0.8601 - val_loss: 0.3375 - val_accuracy: 0.8590\n",
      "Epoch 141/200\n",
      "8000/8000 [==============================] - 2s 247us/step - loss: 0.3359 - accuracy: 0.8624 - val_loss: 0.3372 - val_accuracy: 0.8685\n",
      "Epoch 142/200\n",
      "8000/8000 [==============================] - 1s 176us/step - loss: 0.3371 - accuracy: 0.8616 - val_loss: 0.3402 - val_accuracy: 0.8580\n",
      "Epoch 143/200\n",
      "8000/8000 [==============================] - 2s 192us/step - loss: 0.3360 - accuracy: 0.8606 - val_loss: 0.3364 - val_accuracy: 0.8600\n",
      "Epoch 144/200\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 0.3360 - accuracy: 0.8625 - val_loss: 0.3393 - val_accuracy: 0.8580\n",
      "Epoch 145/200\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.3364 - accuracy: 0.8621 - val_loss: 0.3380 - val_accuracy: 0.8615\n",
      "Epoch 146/200\n",
      "8000/8000 [==============================] - 2s 194us/step - loss: 0.3364 - accuracy: 0.8611 - val_loss: 0.3386 - val_accuracy: 0.8570\n",
      "Epoch 147/200\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.3360 - accuracy: 0.8614 - val_loss: 0.3370 - val_accuracy: 0.8620\n",
      "Epoch 148/200\n",
      "8000/8000 [==============================] - 2s 200us/step - loss: 0.3361 - accuracy: 0.8620 - val_loss: 0.3438 - val_accuracy: 0.8490\n",
      "Epoch 149/200\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.3367 - accuracy: 0.8602 - val_loss: 0.3401 - val_accuracy: 0.8550\n",
      "Epoch 150/200\n",
      "8000/8000 [==============================] - 3s 317us/step - loss: 0.3361 - accuracy: 0.8595 - val_loss: 0.3383 - val_accuracy: 0.8615\n",
      "Epoch 151/200\n",
      "8000/8000 [==============================] - 1s 173us/step - loss: 0.3365 - accuracy: 0.8596 - val_loss: 0.3411 - val_accuracy: 0.8560\n",
      "Epoch 152/200\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 0.3363 - accuracy: 0.8602 - val_loss: 0.3380 - val_accuracy: 0.8605\n",
      "Epoch 153/200\n",
      "8000/8000 [==============================] - 2s 192us/step - loss: 0.3362 - accuracy: 0.8608 - val_loss: 0.3405 - val_accuracy: 0.8555\n",
      "Epoch 154/200\n",
      "8000/8000 [==============================] - 2s 190us/step - loss: 0.3356 - accuracy: 0.8640 - val_loss: 0.3393 - val_accuracy: 0.8570\n",
      "Epoch 155/200\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.3369 - accuracy: 0.8608 - val_loss: 0.3363 - val_accuracy: 0.8595\n",
      "Epoch 156/200\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.3363 - accuracy: 0.8624 - val_loss: 0.3368 - val_accuracy: 0.8590\n",
      "Epoch 157/200\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 0.3365 - accuracy: 0.8609 - val_loss: 0.3367 - val_accuracy: 0.8620\n",
      "Epoch 158/200\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 0.3359 - accuracy: 0.8602 - val_loss: 0.3381 - val_accuracy: 0.8600\n",
      "Epoch 159/200\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.3362 - accuracy: 0.8600 - val_loss: 0.3364 - val_accuracy: 0.8585\n",
      "Epoch 160/200\n",
      "8000/8000 [==============================] - 3s 327us/step - loss: 0.3363 - accuracy: 0.8590 - val_loss: 0.3378 - val_accuracy: 0.8600\n",
      "Epoch 161/200\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.3360 - accuracy: 0.8610 - val_loss: 0.3374 - val_accuracy: 0.8610\n",
      "Epoch 162/200\n",
      "8000/8000 [==============================] - 2s 193us/step - loss: 0.3359 - accuracy: 0.8616 - val_loss: 0.3360 - val_accuracy: 0.8625\n",
      "Epoch 163/200\n",
      "8000/8000 [==============================] - 1s 187us/step - loss: 0.3355 - accuracy: 0.8620 - val_loss: 0.3400 - val_accuracy: 0.8590\n",
      "Epoch 164/200\n",
      "8000/8000 [==============================] - 2s 188us/step - loss: 0.3361 - accuracy: 0.8621 - val_loss: 0.3363 - val_accuracy: 0.8610\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 147us/step - loss: 0.3356 - accuracy: 0.8595 - val_loss: 0.3394 - val_accuracy: 0.8555\n",
      "Epoch 166/200\n",
      "8000/8000 [==============================] - 1s 125us/step - loss: 0.3363 - accuracy: 0.8620 - val_loss: 0.3380 - val_accuracy: 0.8590\n",
      "Epoch 167/200\n",
      "8000/8000 [==============================] - 1s 154us/step - loss: 0.3362 - accuracy: 0.8601 - val_loss: 0.3388 - val_accuracy: 0.8570\n",
      "Epoch 168/200\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 0.3354 - accuracy: 0.8618 - val_loss: 0.3389 - val_accuracy: 0.8575\n",
      "Epoch 169/200\n",
      "8000/8000 [==============================] - 1s 131us/step - loss: 0.3357 - accuracy: 0.8621 - val_loss: 0.3363 - val_accuracy: 0.8595\n",
      "Epoch 170/200\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.3361 - accuracy: 0.8611 - val_loss: 0.3384 - val_accuracy: 0.8590\n",
      "Epoch 171/200\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.3358 - accuracy: 0.8624 - val_loss: 0.3390 - val_accuracy: 0.8600\n",
      "Epoch 172/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.3359 - accuracy: 0.8604 - val_loss: 0.3382 - val_accuracy: 0.8640\n",
      "Epoch 173/200\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 0.3359 - accuracy: 0.8616 - val_loss: 0.3369 - val_accuracy: 0.8620\n",
      "Epoch 174/200\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 0.3352 - accuracy: 0.8615 - val_loss: 0.3350 - val_accuracy: 0.8620\n",
      "Epoch 175/200\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 0.3355 - accuracy: 0.8605 - val_loss: 0.3381 - val_accuracy: 0.8610\n",
      "Epoch 176/200\n",
      "8000/8000 [==============================] - 1s 131us/step - loss: 0.3351 - accuracy: 0.8626 - val_loss: 0.3363 - val_accuracy: 0.8615\n",
      "Epoch 177/200\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 0.3358 - accuracy: 0.8625 - val_loss: 0.3391 - val_accuracy: 0.8585\n",
      "Epoch 178/200\n",
      "8000/8000 [==============================] - 3s 368us/step - loss: 0.3362 - accuracy: 0.8602 - val_loss: 0.3367 - val_accuracy: 0.8620\n",
      "Epoch 179/200\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 0.3361 - accuracy: 0.8591 - val_loss: 0.3384 - val_accuracy: 0.8615\n",
      "Epoch 180/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 0.3355 - accuracy: 0.8627 - val_loss: 0.3386 - val_accuracy: 0.8615\n",
      "Epoch 181/200\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 0.3361 - accuracy: 0.8616 - val_loss: 0.3400 - val_accuracy: 0.8580\n",
      "Epoch 182/200\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.3351 - accuracy: 0.8626 - val_loss: 0.3383 - val_accuracy: 0.8650\n",
      "Epoch 183/200\n",
      "8000/8000 [==============================] - 2s 188us/step - loss: 0.3353 - accuracy: 0.8611 - val_loss: 0.3401 - val_accuracy: 0.8580\n",
      "Epoch 184/200\n",
      "8000/8000 [==============================] - 1s 165us/step - loss: 0.3354 - accuracy: 0.8618 - val_loss: 0.3382 - val_accuracy: 0.8605\n",
      "Epoch 185/200\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 0.3353 - accuracy: 0.8630 - val_loss: 0.3408 - val_accuracy: 0.8580\n",
      "Epoch 186/200\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 0.3355 - accuracy: 0.8636 - val_loss: 0.3379 - val_accuracy: 0.8610\n",
      "Epoch 187/200\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.3353 - accuracy: 0.8619 - val_loss: 0.3379 - val_accuracy: 0.8610\n",
      "Epoch 188/200\n",
      "8000/8000 [==============================] - 1s 161us/step - loss: 0.3353 - accuracy: 0.8615 - val_loss: 0.3391 - val_accuracy: 0.8595\n",
      "Epoch 189/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3343 - accuracy: 0.8618 - val_loss: 0.3416 - val_accuracy: 0.8545\n",
      "Epoch 190/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3351 - accuracy: 0.8620 - val_loss: 0.3391 - val_accuracy: 0.8605\n",
      "Epoch 191/200\n",
      "8000/8000 [==============================] - 1s 159us/step - loss: 0.3355 - accuracy: 0.8608 - val_loss: 0.3380 - val_accuracy: 0.8625\n",
      "Epoch 192/200\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 0.3349 - accuracy: 0.8635 - val_loss: 0.3416 - val_accuracy: 0.8565\n",
      "Epoch 193/200\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 0.3358 - accuracy: 0.8612 - val_loss: 0.3402 - val_accuracy: 0.8580\n",
      "Epoch 194/200\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 0.3344 - accuracy: 0.8637 - val_loss: 0.3371 - val_accuracy: 0.8610\n",
      "Epoch 195/200\n",
      "8000/8000 [==============================] - 2s 270us/step - loss: 0.3354 - accuracy: 0.8641 - val_loss: 0.3372 - val_accuracy: 0.8590\n",
      "Epoch 196/200\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.3347 - accuracy: 0.8605 - val_loss: 0.3404 - val_accuracy: 0.8555\n",
      "Epoch 197/200\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 0.3350 - accuracy: 0.8618 - val_loss: 0.3361 - val_accuracy: 0.8615\n",
      "Epoch 198/200\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 0.3353 - accuracy: 0.8619 - val_loss: 0.3384 - val_accuracy: 0.8605\n",
      "Epoch 199/200\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.3347 - accuracy: 0.8626 - val_loss: 0.3386 - val_accuracy: 0.8605\n",
      "Epoch 200/200\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.3347 - accuracy: 0.8605 - val_loss: 0.3374 - val_accuracy: 0.8610\n",
      "2000/2000 [==============================] - 0s 44us/step\n"
     ]
    }
   ],
   "source": [
    "acc_training = classifier.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=200)\n",
    "acc_testing  = classifier.evaluate(X_test,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akurasinya adalah 0.8610000014305115\n"
     ]
    }
   ],
   "source": [
    "print('akurasinya adalah {}'.format(acc_testing[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.6305841798782349,\n",
       "  0.5863500728607177,\n",
       "  0.42610198402404786,\n",
       "  0.4024295380115509,\n",
       "  0.3982703940868378,\n",
       "  0.3936412292718887,\n",
       "  0.39043821740150453,\n",
       "  0.38674745869636534,\n",
       "  0.38132615625858307,\n",
       "  0.37911401855945587,\n",
       "  0.3754709913730621,\n",
       "  0.3727905408143997,\n",
       "  0.3716309788227081,\n",
       "  0.36843331360816955,\n",
       "  0.3652129392623901,\n",
       "  0.36292798614501953,\n",
       "  0.3641251065731049,\n",
       "  0.3595560941696167,\n",
       "  0.3570224460363388,\n",
       "  0.35713489484786987,\n",
       "  0.35488999271392824,\n",
       "  0.3529081835746765,\n",
       "  0.35320826268196104,\n",
       "  0.35059227180480956,\n",
       "  0.3491491792201996,\n",
       "  0.3502049390077591,\n",
       "  0.3479452464580536,\n",
       "  0.3514718645811081,\n",
       "  0.3448133797645569,\n",
       "  0.34717449259757993,\n",
       "  0.3462997132539749,\n",
       "  0.34643811750411985,\n",
       "  0.34394214034080506,\n",
       "  0.3482433104515076,\n",
       "  0.3440469584465027,\n",
       "  0.3422135463953018,\n",
       "  0.34170296835899355,\n",
       "  0.34182237815856936,\n",
       "  0.3428291759490967,\n",
       "  0.3416092355251312,\n",
       "  0.3439175938367844,\n",
       "  0.3416691575050354,\n",
       "  0.3444209772348404,\n",
       "  0.34215475273132323,\n",
       "  0.3389775930643082,\n",
       "  0.33778056406974794,\n",
       "  0.3375385344028473,\n",
       "  0.3377426211833954,\n",
       "  0.3389311556816101,\n",
       "  0.3396146504878998,\n",
       "  0.3384857556819916,\n",
       "  0.3400629196166992,\n",
       "  0.33602693724632265,\n",
       "  0.3371046936511993,\n",
       "  0.33827556371688844,\n",
       "  0.33852521872520447,\n",
       "  0.336684849858284,\n",
       "  0.3396427925825119,\n",
       "  0.34311569774150846,\n",
       "  0.3374278980493546,\n",
       "  0.3411002207398415,\n",
       "  0.34245819759368895,\n",
       "  0.34447233664989474,\n",
       "  0.340296872317791,\n",
       "  0.33790964663028716,\n",
       "  0.3420025727748871,\n",
       "  0.3352719502449036,\n",
       "  0.33622444087266923,\n",
       "  0.3406100252866745,\n",
       "  0.33821969985961914,\n",
       "  0.3364063038825989,\n",
       "  0.33708003103733064,\n",
       "  0.3360753384232521,\n",
       "  0.33791884952783585,\n",
       "  0.3371646618843079,\n",
       "  0.3382645349502563,\n",
       "  0.3368740476965904,\n",
       "  0.34264782536029814,\n",
       "  0.33984036135673523,\n",
       "  0.33623614501953125,\n",
       "  0.3370933554172516,\n",
       "  0.3372916738986969,\n",
       "  0.33690724170207975,\n",
       "  0.3359086902141571,\n",
       "  0.33629455852508544,\n",
       "  0.3383200044631958,\n",
       "  0.337292777299881,\n",
       "  0.3420507411956787,\n",
       "  0.3412603611946106,\n",
       "  0.3394957426786423,\n",
       "  0.33616861939430237,\n",
       "  0.33850324177742,\n",
       "  0.33834063410758974,\n",
       "  0.3379666930437088,\n",
       "  0.34113338351249695,\n",
       "  0.3375821924209595,\n",
       "  0.3399879665374756,\n",
       "  0.3418472601175308,\n",
       "  0.3375275287628174,\n",
       "  0.33723176729679105,\n",
       "  0.33853351283073424,\n",
       "  0.3404270486831665,\n",
       "  0.33595402097702026,\n",
       "  0.33405289888381956,\n",
       "  0.3376173005104065,\n",
       "  0.3375694353580475,\n",
       "  0.3372508294582367,\n",
       "  0.3374884471893311,\n",
       "  0.33763885486125944,\n",
       "  0.3416679611206055,\n",
       "  0.33752700889110565,\n",
       "  0.33912829411029816,\n",
       "  0.33896236634254456,\n",
       "  0.3457814018726349,\n",
       "  0.3374207729101181,\n",
       "  0.3370206985473633,\n",
       "  0.34203325843811033,\n",
       "  0.3380415964126587,\n",
       "  0.3392348592281342,\n",
       "  0.33760569500923154,\n",
       "  0.34135534167289733,\n",
       "  0.3357086112499237,\n",
       "  0.3377113075256348,\n",
       "  0.3362039248943329,\n",
       "  0.33757765078544616,\n",
       "  0.339127200961113,\n",
       "  0.3367667932510376,\n",
       "  0.33854118847846987,\n",
       "  0.3365262765884399,\n",
       "  0.34108698630332945,\n",
       "  0.33905066061019895,\n",
       "  0.3346711428165436,\n",
       "  0.3385831161737442,\n",
       "  0.34088285255432127,\n",
       "  0.33801981568336487,\n",
       "  0.33819127571582797,\n",
       "  0.33615315580368044,\n",
       "  0.3378308629989624,\n",
       "  0.3415204304456711,\n",
       "  0.3374672381877899,\n",
       "  0.3371512984037399,\n",
       "  0.3402242134809494,\n",
       "  0.3363505846261978,\n",
       "  0.339300302863121,\n",
       "  0.338002153635025,\n",
       "  0.33863992619514466,\n",
       "  0.33696388924121856,\n",
       "  0.3437544165849686,\n",
       "  0.34010953760147095,\n",
       "  0.3382976552248001,\n",
       "  0.34113311100006105,\n",
       "  0.33800486278533937,\n",
       "  0.34045877468585967,\n",
       "  0.3392662823200226,\n",
       "  0.33632570958137514,\n",
       "  0.33680445754528043,\n",
       "  0.33666265952587127,\n",
       "  0.33813576006889345,\n",
       "  0.3364064748287201,\n",
       "  0.33780887341499327,\n",
       "  0.33742816042900087,\n",
       "  0.33599821305274963,\n",
       "  0.34002993679046634,\n",
       "  0.3363371661901474,\n",
       "  0.3393932754993439,\n",
       "  0.3380025931596756,\n",
       "  0.33875682747364044,\n",
       "  0.33893367505073546,\n",
       "  0.3363245928287506,\n",
       "  0.33841865944862365,\n",
       "  0.3390249081850052,\n",
       "  0.3381824609041214,\n",
       "  0.33692018043994904,\n",
       "  0.33503022003173827,\n",
       "  0.33812513935565947,\n",
       "  0.33634364867210387,\n",
       "  0.3390932488441467,\n",
       "  0.33667343378067016,\n",
       "  0.3384253559112549,\n",
       "  0.3386138354539871,\n",
       "  0.3400248411893845,\n",
       "  0.3383282240629196,\n",
       "  0.34005337715148926,\n",
       "  0.3381800087690353,\n",
       "  0.3407573609352112,\n",
       "  0.33794766104221347,\n",
       "  0.33785749006271365,\n",
       "  0.33914291846752165,\n",
       "  0.34156054306030276,\n",
       "  0.3391112117767334,\n",
       "  0.3380106189250946,\n",
       "  0.341563902258873,\n",
       "  0.34021271228790284,\n",
       "  0.3371389520168304,\n",
       "  0.33717489397525785,\n",
       "  0.3404220074415207,\n",
       "  0.3361479651927948,\n",
       "  0.3383926334381103,\n",
       "  0.3386472942829132,\n",
       "  0.33740430474281313],\n",
       " 'val_accuracy': [0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.8345000147819519,\n",
       "  0.8389999866485596,\n",
       "  0.8364999890327454,\n",
       "  0.8379999995231628,\n",
       "  0.8339999914169312,\n",
       "  0.8355000019073486,\n",
       "  0.8389999866485596,\n",
       "  0.8305000066757202,\n",
       "  0.8360000252723694,\n",
       "  0.8355000019073486,\n",
       "  0.8364999890327454,\n",
       "  0.8385000228881836,\n",
       "  0.8374999761581421,\n",
       "  0.8489999771118164,\n",
       "  0.847000002861023,\n",
       "  0.8514999747276306,\n",
       "  0.8519999980926514,\n",
       "  0.8539999723434448,\n",
       "  0.8535000085830688,\n",
       "  0.8519999980926514,\n",
       "  0.8544999957084656,\n",
       "  0.8544999957084656,\n",
       "  0.8529999852180481,\n",
       "  0.8565000295639038,\n",
       "  0.8585000038146973,\n",
       "  0.8544999957084656,\n",
       "  0.8565000295639038,\n",
       "  0.8585000038146973,\n",
       "  0.8554999828338623,\n",
       "  0.8544999957084656,\n",
       "  0.8539999723434448,\n",
       "  0.8569999933242798,\n",
       "  0.8600000143051147,\n",
       "  0.8560000061988831,\n",
       "  0.8544999957084656,\n",
       "  0.8539999723434448,\n",
       "  0.8550000190734863,\n",
       "  0.8544999957084656,\n",
       "  0.8535000085830688,\n",
       "  0.8550000190734863,\n",
       "  0.8539999723434448,\n",
       "  0.8504999876022339,\n",
       "  0.8575000166893005,\n",
       "  0.8554999828338623,\n",
       "  0.8544999957084656,\n",
       "  0.8585000038146973,\n",
       "  0.8579999804496765,\n",
       "  0.8544999957084656,\n",
       "  0.8560000061988831,\n",
       "  0.8519999980926514,\n",
       "  0.859499990940094,\n",
       "  0.8575000166893005,\n",
       "  0.8550000190734863,\n",
       "  0.8550000190734863,\n",
       "  0.8539999723434448,\n",
       "  0.8519999980926514,\n",
       "  0.8525000214576721,\n",
       "  0.8539999723434448,\n",
       "  0.8544999957084656,\n",
       "  0.8539999723434448,\n",
       "  0.8504999876022339,\n",
       "  0.8554999828338623,\n",
       "  0.8569999933242798,\n",
       "  0.8525000214576721,\n",
       "  0.8560000061988831,\n",
       "  0.8560000061988831,\n",
       "  0.8539999723434448,\n",
       "  0.8560000061988831,\n",
       "  0.859499990940094,\n",
       "  0.8565000295639038,\n",
       "  0.8575000166893005,\n",
       "  0.8544999957084656,\n",
       "  0.8550000190734863,\n",
       "  0.8529999852180481,\n",
       "  0.8565000295639038,\n",
       "  0.8510000109672546,\n",
       "  0.8544999957084656,\n",
       "  0.8569999933242798,\n",
       "  0.8565000295639038,\n",
       "  0.8565000295639038,\n",
       "  0.8585000038146973,\n",
       "  0.8575000166893005,\n",
       "  0.8579999804496765,\n",
       "  0.8579999804496765,\n",
       "  0.8529999852180481,\n",
       "  0.8554999828338623,\n",
       "  0.8575000166893005,\n",
       "  0.8560000061988831,\n",
       "  0.8585000038146973,\n",
       "  0.8569999933242798,\n",
       "  0.8585000038146973,\n",
       "  0.8544999957084656,\n",
       "  0.8575000166893005,\n",
       "  0.8579999804496765,\n",
       "  0.8550000190734863,\n",
       "  0.8554999828338623,\n",
       "  0.859499990940094,\n",
       "  0.8579999804496765,\n",
       "  0.859000027179718,\n",
       "  0.8544999957084656,\n",
       "  0.8619999885559082,\n",
       "  0.8610000014305115,\n",
       "  0.8579999804496765,\n",
       "  0.8579999804496765,\n",
       "  0.859000027179718,\n",
       "  0.8615000247955322,\n",
       "  0.8565000295639038,\n",
       "  0.8579999804496765,\n",
       "  0.859499990940094,\n",
       "  0.859499990940094,\n",
       "  0.8579999804496765,\n",
       "  0.8544999957084656,\n",
       "  0.8604999780654907,\n",
       "  0.8640000224113464,\n",
       "  0.8554999828338623,\n",
       "  0.8569999933242798,\n",
       "  0.8575000166893005,\n",
       "  0.859000027179718,\n",
       "  0.8525000214576721,\n",
       "  0.8640000224113464,\n",
       "  0.8560000061988831,\n",
       "  0.8615000247955322,\n",
       "  0.8615000247955322,\n",
       "  0.8610000014305115,\n",
       "  0.8600000143051147,\n",
       "  0.8610000014305115,\n",
       "  0.8604999780654907,\n",
       "  0.859000027179718,\n",
       "  0.8575000166893005,\n",
       "  0.8604999780654907,\n",
       "  0.8575000166893005,\n",
       "  0.8565000295639038,\n",
       "  0.8565000295639038,\n",
       "  0.859000027179718,\n",
       "  0.8600000143051147,\n",
       "  0.8619999885559082,\n",
       "  0.8569999933242798,\n",
       "  0.859000027179718,\n",
       "  0.8684999942779541,\n",
       "  0.8579999804496765,\n",
       "  0.8600000143051147,\n",
       "  0.8579999804496765,\n",
       "  0.8615000247955322,\n",
       "  0.8569999933242798,\n",
       "  0.8619999885559082,\n",
       "  0.8489999771118164,\n",
       "  0.8550000190734863,\n",
       "  0.8615000247955322,\n",
       "  0.8560000061988831,\n",
       "  0.8604999780654907,\n",
       "  0.8554999828338623,\n",
       "  0.8569999933242798,\n",
       "  0.859499990940094,\n",
       "  0.859000027179718,\n",
       "  0.8619999885559082,\n",
       "  0.8600000143051147,\n",
       "  0.8585000038146973,\n",
       "  0.8600000143051147,\n",
       "  0.8610000014305115,\n",
       "  0.862500011920929,\n",
       "  0.859000027179718,\n",
       "  0.8610000014305115,\n",
       "  0.8554999828338623,\n",
       "  0.859000027179718,\n",
       "  0.8569999933242798,\n",
       "  0.8575000166893005,\n",
       "  0.859499990940094,\n",
       "  0.859000027179718,\n",
       "  0.8600000143051147,\n",
       "  0.8640000224113464,\n",
       "  0.8619999885559082,\n",
       "  0.8619999885559082,\n",
       "  0.8610000014305115,\n",
       "  0.8615000247955322,\n",
       "  0.8585000038146973,\n",
       "  0.8619999885559082,\n",
       "  0.8615000247955322,\n",
       "  0.8615000247955322,\n",
       "  0.8579999804496765,\n",
       "  0.8650000095367432,\n",
       "  0.8579999804496765,\n",
       "  0.8604999780654907,\n",
       "  0.8579999804496765,\n",
       "  0.8610000014305115,\n",
       "  0.8610000014305115,\n",
       "  0.859499990940094,\n",
       "  0.8544999957084656,\n",
       "  0.8604999780654907,\n",
       "  0.862500011920929,\n",
       "  0.8565000295639038,\n",
       "  0.8579999804496765,\n",
       "  0.8610000014305115,\n",
       "  0.859000027179718,\n",
       "  0.8554999828338623,\n",
       "  0.8615000247955322,\n",
       "  0.8604999780654907,\n",
       "  0.8604999780654907,\n",
       "  0.8610000014305115],\n",
       " 'loss': [0.6605131843090057,\n",
       "  0.6077162094116211,\n",
       "  0.5336405713558197,\n",
       "  0.41411087483167647,\n",
       "  0.40713722056150436,\n",
       "  0.4026666796207428,\n",
       "  0.3974697375297546,\n",
       "  0.3925463165640831,\n",
       "  0.3883572162389755,\n",
       "  0.3846422139406204,\n",
       "  0.3817927835583687,\n",
       "  0.3788742173910141,\n",
       "  0.3763076455593109,\n",
       "  0.3743921758532524,\n",
       "  0.3718821089267731,\n",
       "  0.370047329723835,\n",
       "  0.3681062685847282,\n",
       "  0.36624306166172027,\n",
       "  0.3648058087527752,\n",
       "  0.36287847644090654,\n",
       "  0.361685168504715,\n",
       "  0.3600739307999611,\n",
       "  0.3590184978246689,\n",
       "  0.3572917905449867,\n",
       "  0.3564503353834152,\n",
       "  0.35587790298461913,\n",
       "  0.3546186512708664,\n",
       "  0.3538711636662483,\n",
       "  0.3533083782196045,\n",
       "  0.35252963662147524,\n",
       "  0.351768506526947,\n",
       "  0.3514136201143265,\n",
       "  0.35060716938972475,\n",
       "  0.3505221312046051,\n",
       "  0.34989986109733584,\n",
       "  0.34893909922242167,\n",
       "  0.34924490690231325,\n",
       "  0.3482600803971291,\n",
       "  0.3479423871934414,\n",
       "  0.34763444155454637,\n",
       "  0.3470992838144302,\n",
       "  0.347186396241188,\n",
       "  0.34669214630126954,\n",
       "  0.34605585220456125,\n",
       "  0.34602081698179243,\n",
       "  0.34546716648340225,\n",
       "  0.34481379881501195,\n",
       "  0.3449668318629265,\n",
       "  0.3442877520918846,\n",
       "  0.343851644217968,\n",
       "  0.3432064568400383,\n",
       "  0.3433308456838131,\n",
       "  0.3425927060544491,\n",
       "  0.3415670328140259,\n",
       "  0.34265074455738065,\n",
       "  0.3418702045083046,\n",
       "  0.3418568284213543,\n",
       "  0.3413209276199341,\n",
       "  0.341661407738924,\n",
       "  0.34163067322969437,\n",
       "  0.341308412104845,\n",
       "  0.3407313595116138,\n",
       "  0.34008636051416397,\n",
       "  0.3401788429617882,\n",
       "  0.34000707161426547,\n",
       "  0.33995482337474825,\n",
       "  0.33971524664759634,\n",
       "  0.3396712525188923,\n",
       "  0.3397072578966618,\n",
       "  0.3394980278611183,\n",
       "  0.3391261355280876,\n",
       "  0.3391622076630592,\n",
       "  0.33876565796136854,\n",
       "  0.33906934052705767,\n",
       "  0.33944704845547674,\n",
       "  0.338356756567955,\n",
       "  0.33891619408130647,\n",
       "  0.3387622930407524,\n",
       "  0.338713434278965,\n",
       "  0.33881038895249366,\n",
       "  0.33871422582864763,\n",
       "  0.3383964122533798,\n",
       "  0.33819451433420183,\n",
       "  0.3383117690682411,\n",
       "  0.33844444376230237,\n",
       "  0.33825087839365003,\n",
       "  0.33796732980012895,\n",
       "  0.33788730439543724,\n",
       "  0.33788556677103043,\n",
       "  0.3388174813389778,\n",
       "  0.33793667089939117,\n",
       "  0.33780535811185836,\n",
       "  0.3379404457509518,\n",
       "  0.3378062228560448,\n",
       "  0.33765910649299624,\n",
       "  0.33788391524553296,\n",
       "  0.33759687846899034,\n",
       "  0.33734637132287026,\n",
       "  0.3378390764594078,\n",
       "  0.33758263784646986,\n",
       "  0.33709316748380663,\n",
       "  0.33681204557418826,\n",
       "  0.3372937725186348,\n",
       "  0.3376166544258595,\n",
       "  0.336548401683569,\n",
       "  0.3370426142215729,\n",
       "  0.3363944556117058,\n",
       "  0.3369237967133522,\n",
       "  0.33727350705862047,\n",
       "  0.33694481617212296,\n",
       "  0.3370869151353836,\n",
       "  0.33714181441068647,\n",
       "  0.33720304775238036,\n",
       "  0.33656452268362047,\n",
       "  0.33746788603067396,\n",
       "  0.3365537709593773,\n",
       "  0.3371602394878864,\n",
       "  0.3366933996081352,\n",
       "  0.33657263666391374,\n",
       "  0.3368545237779617,\n",
       "  0.33677183160185814,\n",
       "  0.3369183130860329,\n",
       "  0.3363295328617096,\n",
       "  0.336522883862257,\n",
       "  0.3372214304804802,\n",
       "  0.3363225354552269,\n",
       "  0.3367303705811501,\n",
       "  0.3366403658986092,\n",
       "  0.33649590170383453,\n",
       "  0.3366950318217278,\n",
       "  0.3369336007833481,\n",
       "  0.33682106697559355,\n",
       "  0.3373604662418365,\n",
       "  0.3363962067961693,\n",
       "  0.3368538422882557,\n",
       "  0.33647999957203867,\n",
       "  0.3364184054136276,\n",
       "  0.336371420621872,\n",
       "  0.3363167344331741,\n",
       "  0.33629449874162676,\n",
       "  0.3359247942268848,\n",
       "  0.3371229826807976,\n",
       "  0.3359846637845039,\n",
       "  0.3360327458679676,\n",
       "  0.3363794779777527,\n",
       "  0.3363856339454651,\n",
       "  0.3360293204188347,\n",
       "  0.33608292001485823,\n",
       "  0.3366838937997818,\n",
       "  0.3361262482404709,\n",
       "  0.3364661630690098,\n",
       "  0.33629902294278147,\n",
       "  0.3361705053448677,\n",
       "  0.33556854966282845,\n",
       "  0.3369492114782333,\n",
       "  0.3362963199019432,\n",
       "  0.33653712129592894,\n",
       "  0.3359039671123028,\n",
       "  0.3362053002119064,\n",
       "  0.33630433422327044,\n",
       "  0.33595098185539246,\n",
       "  0.3359026010632515,\n",
       "  0.33548242431879044,\n",
       "  0.3360799495577812,\n",
       "  0.3356001663208008,\n",
       "  0.3363011333346367,\n",
       "  0.33618425810337066,\n",
       "  0.335389257311821,\n",
       "  0.33572496980428695,\n",
       "  0.33606949216127396,\n",
       "  0.3357936705350876,\n",
       "  0.3358524934053421,\n",
       "  0.33594394409656525,\n",
       "  0.3352446323633194,\n",
       "  0.3355259637236595,\n",
       "  0.335138321518898,\n",
       "  0.33579540032148364,\n",
       "  0.3361507612466812,\n",
       "  0.33610403710603715,\n",
       "  0.3354790817797184,\n",
       "  0.3360665067434311,\n",
       "  0.33508439964056014,\n",
       "  0.335276370793581,\n",
       "  0.33536838507652283,\n",
       "  0.33531244108080865,\n",
       "  0.33545069450139997,\n",
       "  0.3353211731910706,\n",
       "  0.33532493525743484,\n",
       "  0.3342995519042015,\n",
       "  0.33505002850294113,\n",
       "  0.3354587435722351,\n",
       "  0.3348734012246132,\n",
       "  0.3357767483890057,\n",
       "  0.3344008444547653,\n",
       "  0.3354199355840683,\n",
       "  0.33466875022649767,\n",
       "  0.3349711694717407,\n",
       "  0.33534578189253805,\n",
       "  0.33470353680849074,\n",
       "  0.33472781619429587],\n",
       " 'accuracy': [0.792875,\n",
       "  0.796,\n",
       "  0.801,\n",
       "  0.826375,\n",
       "  0.831,\n",
       "  0.830875,\n",
       "  0.832125,\n",
       "  0.83325,\n",
       "  0.833125,\n",
       "  0.83525,\n",
       "  0.835125,\n",
       "  0.834375,\n",
       "  0.834375,\n",
       "  0.83375,\n",
       "  0.837,\n",
       "  0.84325,\n",
       "  0.847125,\n",
       "  0.852125,\n",
       "  0.849875,\n",
       "  0.851625,\n",
       "  0.8535,\n",
       "  0.852875,\n",
       "  0.854125,\n",
       "  0.8545,\n",
       "  0.85425,\n",
       "  0.85425,\n",
       "  0.85625,\n",
       "  0.85575,\n",
       "  0.85525,\n",
       "  0.856125,\n",
       "  0.856125,\n",
       "  0.8565,\n",
       "  0.858125,\n",
       "  0.857625,\n",
       "  0.856875,\n",
       "  0.857125,\n",
       "  0.856,\n",
       "  0.85875,\n",
       "  0.856875,\n",
       "  0.85875,\n",
       "  0.8575,\n",
       "  0.85775,\n",
       "  0.85675,\n",
       "  0.857875,\n",
       "  0.857625,\n",
       "  0.8585,\n",
       "  0.8575,\n",
       "  0.85875,\n",
       "  0.859125,\n",
       "  0.858625,\n",
       "  0.85925,\n",
       "  0.858375,\n",
       "  0.858875,\n",
       "  0.859875,\n",
       "  0.8585,\n",
       "  0.858625,\n",
       "  0.858875,\n",
       "  0.859625,\n",
       "  0.860125,\n",
       "  0.8585,\n",
       "  0.85775,\n",
       "  0.86175,\n",
       "  0.86025,\n",
       "  0.85875,\n",
       "  0.86,\n",
       "  0.859125,\n",
       "  0.860875,\n",
       "  0.8595,\n",
       "  0.85925,\n",
       "  0.85825,\n",
       "  0.857875,\n",
       "  0.85825,\n",
       "  0.8605,\n",
       "  0.859875,\n",
       "  0.861,\n",
       "  0.86025,\n",
       "  0.86025,\n",
       "  0.86,\n",
       "  0.86075,\n",
       "  0.858625,\n",
       "  0.862,\n",
       "  0.860875,\n",
       "  0.861125,\n",
       "  0.859875,\n",
       "  0.859375,\n",
       "  0.858,\n",
       "  0.861375,\n",
       "  0.8585,\n",
       "  0.8595,\n",
       "  0.8605,\n",
       "  0.859875,\n",
       "  0.859625,\n",
       "  0.8605,\n",
       "  0.861,\n",
       "  0.861625,\n",
       "  0.859625,\n",
       "  0.859375,\n",
       "  0.861125,\n",
       "  0.8615,\n",
       "  0.85875,\n",
       "  0.859375,\n",
       "  0.861625,\n",
       "  0.860875,\n",
       "  0.86025,\n",
       "  0.860625,\n",
       "  0.859125,\n",
       "  0.861,\n",
       "  0.86075,\n",
       "  0.861625,\n",
       "  0.8605,\n",
       "  0.861125,\n",
       "  0.861875,\n",
       "  0.86125,\n",
       "  0.859125,\n",
       "  0.86,\n",
       "  0.859375,\n",
       "  0.86175,\n",
       "  0.86,\n",
       "  0.861625,\n",
       "  0.861375,\n",
       "  0.86025,\n",
       "  0.861125,\n",
       "  0.86125,\n",
       "  0.859625,\n",
       "  0.860125,\n",
       "  0.8605,\n",
       "  0.86,\n",
       "  0.861125,\n",
       "  0.8605,\n",
       "  0.861125,\n",
       "  0.860125,\n",
       "  0.85975,\n",
       "  0.859875,\n",
       "  0.861625,\n",
       "  0.861,\n",
       "  0.86225,\n",
       "  0.8595,\n",
       "  0.862375,\n",
       "  0.862875,\n",
       "  0.860125,\n",
       "  0.862375,\n",
       "  0.861625,\n",
       "  0.860625,\n",
       "  0.8625,\n",
       "  0.862125,\n",
       "  0.861125,\n",
       "  0.861375,\n",
       "  0.862,\n",
       "  0.86025,\n",
       "  0.8595,\n",
       "  0.859625,\n",
       "  0.86025,\n",
       "  0.86075,\n",
       "  0.864,\n",
       "  0.86075,\n",
       "  0.862375,\n",
       "  0.860875,\n",
       "  0.86025,\n",
       "  0.86,\n",
       "  0.859,\n",
       "  0.861,\n",
       "  0.861625,\n",
       "  0.862,\n",
       "  0.862125,\n",
       "  0.8595,\n",
       "  0.862,\n",
       "  0.860125,\n",
       "  0.86175,\n",
       "  0.862125,\n",
       "  0.861125,\n",
       "  0.862375,\n",
       "  0.860375,\n",
       "  0.861625,\n",
       "  0.8615,\n",
       "  0.8605,\n",
       "  0.862625,\n",
       "  0.8625,\n",
       "  0.86025,\n",
       "  0.859125,\n",
       "  0.86275,\n",
       "  0.861625,\n",
       "  0.862625,\n",
       "  0.861125,\n",
       "  0.86175,\n",
       "  0.863,\n",
       "  0.863625,\n",
       "  0.861875,\n",
       "  0.8615,\n",
       "  0.86175,\n",
       "  0.862,\n",
       "  0.86075,\n",
       "  0.8635,\n",
       "  0.86125,\n",
       "  0.86375,\n",
       "  0.864125,\n",
       "  0.8605,\n",
       "  0.86175,\n",
       "  0.861875,\n",
       "  0.862625,\n",
       "  0.8605]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_training.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Model Akurasi dan Loss Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,(ax0) = plt.subplots(nrows=1, figsize=(12,5))\n",
    "ax0.plot(acc_training.history['accuracy'],'red', label='Akurasi Training')\n",
    "ax0.plot(acc_training.history['val_accuracy'], 'blue', label='Akurasi Validasi')\n",
    "ax0.plot(label='Accuracy', loc='upper left')\n",
    "ax0.set_title('Model Accuracy')\n",
    "ax0.set_xlabel(\"Epoch\")\n",
    "ax0.set_ylabel(\"Accuracy\")\n",
    "ax0.legend()\n",
    "plt.savefig('Grafik Akurasi.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,(ax1) = plt.subplots(nrows=1, figsize=(12,5))\n",
    "ax1.plot(acc_training.history['loss'],'red', label='Loss Training')\n",
    "ax1.plot(acc_training.history['val_loss'], 'blue', label='Loss Validasi')\n",
    "ax1.plot(label='Loss', loc='upper left')\n",
    "ax1.set_title('Model Loss')\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend()\n",
    "plt.savefig('Grafik Loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predicted = classifier.predict(X_train)\n",
    "testing_predicted = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_predicted.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriks Confusion\n",
    "Confusion matrix merupakan salah satu metode yang dapat digunakan untuk mengukur kinerja suatu metode klasifikasi. Pada dasarnya confusion matrix mengandung informasi yang membandingkan hasil klasifikasi yang dilakukan oleh sistem dengan hasil klasifikasi yang seharusnya.\n",
    "\n",
    "Berdasarkan jumlah keluaran kelasnya, sistem klasifikasi dapat dibagi menjadi 4 (empat) jenis yaitu :\n",
    "- klasifikasi binary\n",
    "- multi-class\n",
    "- multi-label \n",
    "- hierarchical\n",
    "\n",
    "Pada pengukuran kinerja menggunakan confusion matrix, terdapat 4 (empat) istilah sebagai representasi hasil proses klasifikasi. Keempat istilah tersebut adalah:\n",
    "\n",
    "1) True Positive (TP)\n",
    "\n",
    "2) True Negative (TN)\n",
    "\n",
    "3) False Positive (FP) \n",
    "\n",
    "4) False Negative (FN)\n",
    "- True Negative (TN) merupakan jumlah data negatif yang terdeteksi dengan benar, \n",
    "- sedangkan False Positive (FP) merupakan data negatif namun terdeteksi sebagai data positif. Sementara itu, \n",
    "- True Positive (TP) merupakan data positif yang terdeteksi benar.\n",
    "- False Negative (FN) merupakan kebalikan dari True Positive, sehingga data posifit, namun terdeteksi sebagai data negatif.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Berdasarkan nilai True Negative (TN), False Positive (FP), False Negative (FN), dan True Positive (TP) dapat diperoleh nilai Accuracy, Specificity, Sensitivity, Precision, dan F1 Score.Untuk memperoleh nilai akurasi, presisi dan recall kita dapat menggunakan rumus :\n",
    "\n",
    "$$Accuracy = \\frac {tp+tn}{tp+tn+fp+fn}$$\n",
    "\n",
    "$$Specificity = \\frac {tn}{tn+fp}$$\n",
    "\n",
    "$$Sensitivity = \\frac {tp}{tp+fn}$$\n",
    "\n",
    "$$Precision = \\frac {tp}{tp+fp}$$\n",
    "\n",
    "$$F1 Score = \\frac {2 \\times Sensitivity \\times Precision}{Sensitivity+ Precision}$$\n",
    "\n",
    "Menghitung Confusion Matrix pada dataset yang telah diolah, kita deklarasikan model predict dari data training dan data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "training_cm = confusion_matrix(y_train,training_predicted.round())\n",
    "testing_cm = confusion_matrix(y_test,testing_predicted.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil Confusion Matrix dari data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6108,  260],\n",
       "       [ 838,  794]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil perolehan nilai Accuracy, Specificity, Sensitivity, Precision, dan F1 Score pada data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training 0.86275\n",
      "Specificity training 0.48651960784313725\n",
      "Sensitivity training 0.9591708542713567\n",
      "Precision training 0.8793550244745177\n",
      "F1 Score training 0.9175304191077062\n"
     ]
    }
   ],
   "source": [
    "tp = training_cm[0][0]\n",
    "fn = training_cm[0][1]\n",
    "fp = training_cm[1][0]\n",
    "tn = training_cm[1][1]\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f1_score = (2*sensitivity*precision)/(sensitivity+precision)\n",
    "\n",
    "print(\"Accuracy training {0}\".format(accuracy))\n",
    "print(\"Specificity training {0}\".format(specificity))\n",
    "print(\"Sensitivity training {0}\".format(sensitivity))\n",
    "print(\"Precision training {0}\".format(precision))\n",
    "print(\"F1 Score training {0}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil Confusion Matrix dari data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1516,   79],\n",
       "       [ 199,  206]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil perolehan nilai Accuracy, Specificity, Sensitivity, Precision, dan F1 Score pada data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy testing 0.861\n",
      "Specificity testing 0.508641975308642\n",
      "Sensitivity testing 0.9504702194357367\n",
      "Precision testing 0.8839650145772595\n",
      "F1 Score testing 0.9160120845921451\n"
     ]
    }
   ],
   "source": [
    "tp = testing_cm[0][0]\n",
    "fn = testing_cm[0][1]\n",
    "fp = testing_cm[1][0]\n",
    "tn = testing_cm[1][1]\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f1_score = (2*sensitivity*precision)/(sensitivity+precision)\n",
    "\n",
    "print(\"Accuracy testing {0}\".format(accuracy))\n",
    "print(\"Specificity testing {0}\".format(specificity))\n",
    "print(\"Sensitivity testing {0}\".format(sensitivity))\n",
    "print(\"Precision testing {0}\".format(precision))\n",
    "print(\"F1 Score testing {0}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Referensi \n",
    "- Paper : Customer churn prediction by hybrid neural networks\n",
    "- dataset : https://www.kaggle.com/barelydedicated/bank-churn-rate-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
