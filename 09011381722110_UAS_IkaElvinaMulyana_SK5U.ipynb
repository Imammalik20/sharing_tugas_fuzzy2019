{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## LUNG CANCER ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAMA : IKA ELVINA MULYANA\n",
    "\n",
    "NIM : 09011381722110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kanker paru-paru adalah salah satu penyakit paling umum dan mematikan di dunia. Deteksi kanker paru-paru pada tahap awal adalah kunci penyembuhannya. Secara umum, langkah-langkah untuk diagnosis kanker paru stadium awal terutama mencakup mereka yang menggunakan X-ray film dada, CT, MRI, isotop, bronkoskopi, dll., Di antaranya pengukuran yang sangat penting adalah apa yang disebut diagnosis patologis yang menganalisis spesimen jarum. biopsi diperoleh dari tubuh subjek yang akan didiagnosis. Saat ini, spesimen biopsi jarum biasanya dianalisis oleh ahli patologi berpengalaman. Karena patolog senior jarang, diagnosis patologis yang andal tidak selalu tersedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA SET\n",
    "\n",
    "1. INFORMASI DATA SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset didapat dari UCI MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ATRIBUT DATASET\n",
    "\n",
    "0) Hasil biner dari penilaian pasien. 0 = didiagnosa normal(Tidak Sakit) 1 = didiagnosa sakit.\n",
    "1) Hasil biner dari pra-screening, di mana 1 menunjukkan bahwa didiagnosa mengalami lung cancer dan 0 kekurangannya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORT LIBRARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. model yang digunakan untuk membuat hidden layer untuk memproses data adalah fungsi Sequential.  Sedangkan layer sendiri menggunakan tipe Dense yang melakukan training dengan menghubungkan setiap Neural Network secara sequential.\n",
    "\n",
    "2. Numpy dan Pandas, Tentu saja untuk mengolah data yang berupa angka memerlukan Number Python sebagai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INPUT DATASET\n",
    "Dataset yang digunakan menggunakan format .csv yang merupakan data vektor yang berisi angka-angka sehingga dapat diproses oleh IDE dengan lebih mudah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv (\"lung-cancer.csv\")\n",
    "feature = np.array(dataset.ix[:, 0:56])\n",
    "label = np.array(dataset.ix[:, 56])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preprocessing\n",
    "preprocessing mengubah data menjadi format yang akan lebih mudah dan efektif diproses dalam jaringan saraf. Ada sejumlah alat dan metode yang berbeda yang dapat digunakan untuk preprocessing, contohnya yaitu: transformasi yang memanipulasi data mentah untuk menghasilkan satu input, denoising yang menghilangkan noise dari data, dan lain sebagainya.\n",
    "\n",
    "#### 2. Categorical\n",
    "untuk mengkonversi data binary menjadi data yang dapat dikkelompokkan, sehingga data tersebut dapat diambil bagian-bagiannya sebagai sebuah confusion matrix.\n",
    "\n",
    "#### 3. Confusion Matrix\n",
    "untuk mengkalkulasi dan mengelompokkan data menjadi sebuah matrix 2x2 yang didalamnya terdapat data prediksi dan data aktual dari dataset yang telah ditraining. parameter yang digunakan dalam confusion matrix adalah data Categorical dan prediksi hasil training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "feature_scaled=scaler.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 56)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 1 2 2 1 1 1 2 1 1 2 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "label_categorical=to_categorical(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CATEGORICAL\n",
    "\n",
    "membuat confusion matrix adalah dengan mengubah kasifikasi data yang pada awalnya binary classification menjadi categorical classification, namun begitu dalam proses ini sebenarnya tidak mengubah makna awal dari dataset tersebut yang berklasifikasikan secara binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 3)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_categorical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MENDEFISIKAN MODEL\n",
    "Sebagaimana yang telah dijelaskan diatas, bahwasanya model yang digunakan dalam kasus ini menggunakan fungsi Sequential.  Dimana hidden layer yang saya buat untuk memproses dataset lung cancer ini memiliki 9 layer dengan masing-masing masing-masing berparameterkan:\n",
    "1. Input 8 layer -> 50 units Neural Network, 57 dimensi input, 8 activation relu.\n",
    "2. Output 1 layer -> 3 unit Neural Network dengan menggunakan activation softmax (karena data sudah diubah menjadi categorical, jika tidak maka gunakan activation sigmoid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=56, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPILE MODEL\n",
    "Setelah melakukan proses definisi model, selanjutnya dalah mengcompile model tersebut sehingga menjadi satu kesatuan hidden yang biasa disebut dengan Hidden Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  FIT MODEL\n",
    "Untuk mendapatkan hasil akurasi dan loss dari dataset, langkah selanjutnya yang harus dilakukan adalah fit model.  Dimana pada proses ini terjadi proses training dengan parameter:\n",
    "1. X yang telah di preprocessing\n",
    "2. Y yang telah dikonversi menjadi categorical\n",
    "3. Banyaknya Epochs atau proses training\n",
    "4. batch_size\n",
    "\n",
    "Disini Epochs atau training yang saya lakukan adalah sebanya 200 kali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21 samples, validate on 10 samples\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 2s 72ms/step - loss: 1.0558 - accuracy: 0.8571 - val_loss: 1.0907 - val_accuracy: 0.4000\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0261 - accuracy: 0.8571 - val_loss: 1.0899 - val_accuracy: 0.4000\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 950us/step - loss: 0.9923 - accuracy: 0.8571 - val_loss: 1.0895 - val_accuracy: 0.4000\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 525us/step - loss: 0.9501 - accuracy: 0.8571 - val_loss: 1.0915 - val_accuracy: 0.4000\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9046 - accuracy: 0.8571 - val_loss: 1.0913 - val_accuracy: 0.4000\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8587 - accuracy: 0.8571 - val_loss: 1.0877 - val_accuracy: 0.4000\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 726us/step - loss: 0.8159 - accuracy: 0.8571 - val_loss: 1.0872 - val_accuracy: 0.4000\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 712us/step - loss: 0.7659 - accuracy: 0.8571 - val_loss: 1.0900 - val_accuracy: 0.4000\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.7128 - accuracy: 0.8571 - val_loss: 1.0895 - val_accuracy: 0.4000\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.85 - 0s 1ms/step - loss: 0.6575 - accuracy: 0.8571 - val_loss: 1.0855 - val_accuracy: 0.4000\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.8571 - val_loss: 1.0792 - val_accuracy: 0.4000\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 978us/step - loss: 0.5648 - accuracy: 0.8571 - val_loss: 1.0697 - val_accuracy: 0.4000\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.8571 - val_loss: 1.0743 - val_accuracy: 0.4000\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8571 - val_loss: 1.1010 - val_accuracy: 0.4000\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 856us/step - loss: 0.4485 - accuracy: 0.8571 - val_loss: 1.1594 - val_accuracy: 0.4000\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8571 - val_loss: 1.2572 - val_accuracy: 0.4000\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 616us/step - loss: 0.3988 - accuracy: 0.8571 - val_loss: 1.3985 - val_accuracy: 0.4000\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 473us/step - loss: 0.4061 - accuracy: 0.8571 - val_loss: 1.4619 - val_accuracy: 0.4000\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 434us/step - loss: 0.4023 - accuracy: 0.8571 - val_loss: 1.4246 - val_accuracy: 0.4000\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8571 - val_loss: 1.4030 - val_accuracy: 0.4000\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8571 - val_loss: 1.3959 - val_accuracy: 0.4000\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 380us/step - loss: 0.3892 - accuracy: 0.8571 - val_loss: 1.3321 - val_accuracy: 0.4000\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.3788 - accuracy: 0.8571 - val_loss: 1.2061 - val_accuracy: 0.4000\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.3805 - accuracy: 0.8571 - val_loss: 1.1096 - val_accuracy: 0.4000\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3842 - accuracy: 0.8571 - val_loss: 1.0412 - val_accuracy: 0.4000\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 540us/step - loss: 0.3998 - accuracy: 0.8571 - val_loss: 0.9914 - val_accuracy: 0.4000\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.4143 - accuracy: 0.8571 - val_loss: 0.9667 - val_accuracy: 0.4000\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 665us/step - loss: 0.4232 - accuracy: 0.8571 - val_loss: 0.9588 - val_accuracy: 0.4000\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 388us/step - loss: 0.4257 - accuracy: 0.8571 - val_loss: 0.9632 - val_accuracy: 0.4000\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.8571 - val_loss: 0.9780 - val_accuracy: 0.4000\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 568us/step - loss: 0.4151 - accuracy: 0.8571 - val_loss: 1.0028 - val_accuracy: 0.4000\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 943us/step - loss: 0.4048 - accuracy: 0.8571 - val_loss: 1.0382 - val_accuracy: 0.4000\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 699us/step - loss: 0.3934 - accuracy: 0.8571 - val_loss: 1.0850 - val_accuracy: 0.4000\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 665us/step - loss: 0.3824 - accuracy: 0.8571 - val_loss: 1.1435 - val_accuracy: 0.4000\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.85 - 0s 525us/step - loss: 0.3739 - accuracy: 0.8571 - val_loss: 1.2140 - val_accuracy: 0.4000\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 850us/step - loss: 0.3688 - accuracy: 0.8571 - val_loss: 1.2941 - val_accuracy: 0.4000\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 451us/step - loss: 0.3679 - accuracy: 0.8571 - val_loss: 1.3794 - val_accuracy: 0.4000\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.3712 - accuracy: 0.8571 - val_loss: 1.4623 - val_accuracy: 0.4000\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3772 - accuracy: 0.8571 - val_loss: 1.5372 - val_accuracy: 0.4000\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8571 - val_loss: 1.6014 - val_accuracy: 0.4000\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 834us/step - loss: 0.3915 - accuracy: 0.8571 - val_loss: 1.6506 - val_accuracy: 0.4000\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 532us/step - loss: 0.3972 - accuracy: 0.8571 - val_loss: 1.6839 - val_accuracy: 0.4000\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 760us/step - loss: 0.4009 - accuracy: 0.8571 - val_loss: 1.6999 - val_accuracy: 0.4000\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 615us/step - loss: 0.4021 - accuracy: 0.8571 - val_loss: 1.7057 - val_accuracy: 0.4000\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4017 - accuracy: 0.8571 - val_loss: 1.7081 - val_accuracy: 0.4000\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 546us/step - loss: 0.4008 - accuracy: 0.8571 - val_loss: 1.7060 - val_accuracy: 0.4000\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 617us/step - loss: 0.3990 - accuracy: 0.8571 - val_loss: 1.6949 - val_accuracy: 0.4000\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 382us/step - loss: 0.3959 - accuracy: 0.8571 - val_loss: 1.6728 - val_accuracy: 0.4000\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 523us/step - loss: 0.3916 - accuracy: 0.8571 - val_loss: 1.6472 - val_accuracy: 0.4000\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 420us/step - loss: 0.3867 - accuracy: 0.8571 - val_loss: 1.6214 - val_accuracy: 0.4000\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 391us/step - loss: 0.3806 - accuracy: 0.8571 - val_loss: 1.5308 - val_accuracy: 0.4000\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 427us/step - loss: 0.3701 - accuracy: 0.8571 - val_loss: 1.4122 - val_accuracy: 0.4000\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 443us/step - loss: 0.3584 - accuracy: 0.8571 - val_loss: 1.3368 - val_accuracy: 0.4000\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 380us/step - loss: 0.3537 - accuracy: 0.8571 - val_loss: 1.2900 - val_accuracy: 0.4000\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8571 - val_loss: 1.2645 - val_accuracy: 0.4000\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 435us/step - loss: 0.3514 - accuracy: 0.8571 - val_loss: 1.2594 - val_accuracy: 0.4000\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8571 - val_loss: 1.2726 - val_accuracy: 0.4000\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 427us/step - loss: 0.3490 - accuracy: 0.8571 - val_loss: 1.3011 - val_accuracy: 0.4000\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 616us/step - loss: 0.3475 - accuracy: 0.8571 - val_loss: 1.3417 - val_accuracy: 0.4000\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.3490 - accuracy: 0.8571 - val_loss: 1.3248 - val_accuracy: 0.4000\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 526us/step - loss: 0.3459 - accuracy: 0.8571 - val_loss: 1.2637 - val_accuracy: 0.4000\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 332us/step - loss: 0.3457 - accuracy: 0.8571 - val_loss: 1.2302 - val_accuracy: 0.4000\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 523us/step - loss: 0.3456 - accuracy: 0.8571 - val_loss: 1.1955 - val_accuracy: 0.4000\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 855us/step - loss: 0.3480 - accuracy: 0.8571 - val_loss: 1.1619 - val_accuracy: 0.4000\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 760us/step - loss: 0.3505 - accuracy: 0.8571 - val_loss: 1.1500 - val_accuracy: 0.4000\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 489us/step - loss: 0.3508 - accuracy: 0.8571 - val_loss: 1.1555 - val_accuracy: 0.4000\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 696us/step - loss: 0.3486 - accuracy: 0.8571 - val_loss: 1.1762 - val_accuracy: 0.4000\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 584us/step - loss: 0.3460 - accuracy: 0.8571 - val_loss: 1.1754 - val_accuracy: 0.4000\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 807us/step - loss: 0.3437 - accuracy: 0.8571 - val_loss: 1.1563 - val_accuracy: 0.4000\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 948us/step - loss: 0.3449 - accuracy: 0.8571 - val_loss: 1.1566 - val_accuracy: 0.4000\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8571 - val_loss: 1.1731 - val_accuracy: 0.4000\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 521us/step - loss: 0.3400 - accuracy: 0.8571 - val_loss: 1.2023 - val_accuracy: 0.4000\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8571 - val_loss: 1.2425 - val_accuracy: 0.4000\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 898us/step - loss: 0.3309 - accuracy: 0.8571 - val_loss: 1.2928 - val_accuracy: 0.4000\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 567us/step - loss: 0.3273 - accuracy: 0.8571 - val_loss: 1.3507 - val_accuracy: 0.4000\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 531us/step - loss: 0.3248 - accuracy: 0.8571 - val_loss: 1.4168 - val_accuracy: 0.4000\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 712us/step - loss: 0.3243 - accuracy: 0.8571 - val_loss: 1.4877 - val_accuracy: 0.4000\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 427us/step - loss: 0.3259 - accuracy: 0.8571 - val_loss: 1.5527 - val_accuracy: 0.4000\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 617us/step - loss: 0.3283 - accuracy: 0.8571 - val_loss: 1.6113 - val_accuracy: 0.4000\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 783us/step - loss: 0.3310 - accuracy: 0.8571 - val_loss: 1.6588 - val_accuracy: 0.4000\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 840us/step - loss: 0.3329 - accuracy: 0.8571 - val_loss: 1.6932 - val_accuracy: 0.4000\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 664us/step - loss: 0.3342 - accuracy: 0.8571 - val_loss: 1.7167 - val_accuracy: 0.4000\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 428us/step - loss: 0.3346 - accuracy: 0.8571 - val_loss: 1.7318 - val_accuracy: 0.4000\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.3339 - accuracy: 0.8571 - val_loss: 1.7396 - val_accuracy: 0.4000\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.3324 - accuracy: 0.8571 - val_loss: 1.7369 - val_accuracy: 0.4000\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 753us/step - loss: 0.3299 - accuracy: 0.8571 - val_loss: 1.7235 - val_accuracy: 0.4000\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 428us/step - loss: 0.3255 - accuracy: 0.8571 - val_loss: 1.6030 - val_accuracy: 0.4000\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3146 - accuracy: 0.8571 - val_loss: 1.4308 - val_accuracy: 0.4000\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 429us/step - loss: 0.3070 - accuracy: 0.8571 - val_loss: 1.3259 - val_accuracy: 0.4000\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 714us/step - loss: 0.3073 - accuracy: 0.8571 - val_loss: 1.2689 - val_accuracy: 0.4000\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 805us/step - loss: 0.3095 - accuracy: 0.8571 - val_loss: 1.2400 - val_accuracy: 0.4000\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 590us/step - loss: 0.3110 - accuracy: 0.8571 - val_loss: 1.2329 - val_accuracy: 0.4000\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 598us/step - loss: 0.3103 - accuracy: 0.8571 - val_loss: 1.2460 - val_accuracy: 0.4000\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 427us/step - loss: 0.3074 - accuracy: 0.8571 - val_loss: 1.2753 - val_accuracy: 0.4000\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8571 - val_loss: 1.3169 - val_accuracy: 0.4000\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 900us/step - loss: 0.2984 - accuracy: 0.8571 - val_loss: 1.3720 - val_accuracy: 0.4000\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.8571 - val_loss: 1.4406 - val_accuracy: 0.4000\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 572us/step - loss: 0.2930 - accuracy: 0.8571 - val_loss: 1.4532 - val_accuracy: 0.4000\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8571 - val_loss: 1.4150 - val_accuracy: 0.4000\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 611us/step - loss: 0.2846 - accuracy: 0.8571 - val_loss: 1.3727 - val_accuracy: 0.4000\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 807us/step - loss: 0.2838 - accuracy: 0.8571 - val_loss: 1.3353 - val_accuracy: 0.4000\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.8571 - val_loss: 1.3273 - val_accuracy: 0.4000\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.8571 - val_loss: 1.3123 - val_accuracy: 0.4000\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8571 - val_loss: 1.2962 - val_accuracy: 0.4000\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.2764 - accuracy: 0.8571 - val_loss: 1.3087 - val_accuracy: 0.4000\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 663us/step - loss: 0.2711 - accuracy: 0.8571 - val_loss: 1.3462 - val_accuracy: 0.4000\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 712us/step - loss: 0.2645 - accuracy: 0.8571 - val_loss: 1.4055 - val_accuracy: 0.4000\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.8571 - val_loss: 1.4821 - val_accuracy: 0.4000\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 620us/step - loss: 0.2517 - accuracy: 0.8571 - val_loss: 1.5826 - val_accuracy: 0.4000\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.8571 - val_loss: 1.6973 - val_accuracy: 0.4000\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 621us/step - loss: 0.2510 - accuracy: 0.8571 - val_loss: 1.7111 - val_accuracy: 0.4000\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.8571 - val_loss: 1.6394 - val_accuracy: 0.4000\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 573us/step - loss: 0.2397 - accuracy: 0.8571 - val_loss: 1.5692 - val_accuracy: 0.4000\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 389us/step - loss: 0.2372 - accuracy: 0.8571 - val_loss: 1.4988 - val_accuracy: 0.4000\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 476us/step - loss: 0.2363 - accuracy: 0.8571 - val_loss: 1.4674 - val_accuracy: 0.4000\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.2350 - accuracy: 0.8571 - val_loss: 1.4726 - val_accuracy: 0.4000\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.8571 - val_loss: 1.5026 - val_accuracy: 0.4000\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 527us/step - loss: 0.2292 - accuracy: 0.8571 - val_loss: 1.5559 - val_accuracy: 0.4000\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 644us/step - loss: 0.2265 - accuracy: 0.8571 - val_loss: 1.5498 - val_accuracy: 0.4000\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.2229 - accuracy: 0.8571 - val_loss: 1.4962 - val_accuracy: 0.4000\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 806us/step - loss: 0.2238 - accuracy: 0.8571 - val_loss: 1.4834 - val_accuracy: 0.4000\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.8571 - val_loss: 1.4928 - val_accuracy: 0.4000\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 537us/step - loss: 0.2209 - accuracy: 0.8571 - val_loss: 1.5196 - val_accuracy: 0.4000\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 902us/step - loss: 0.2171 - accuracy: 0.8571 - val_loss: 1.5815 - val_accuracy: 0.4000\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 514us/step - loss: 0.2120 - accuracy: 0.8571 - val_loss: 1.6743 - val_accuracy: 0.4000\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 857us/step - loss: 0.2066 - accuracy: 0.8571 - val_loss: 1.7770 - val_accuracy: 0.4000\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.2024 - accuracy: 0.8571 - val_loss: 1.8720 - val_accuracy: 0.4000\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.8571 - val_loss: 1.9610 - val_accuracy: 0.4000\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.1967 - accuracy: 0.8571 - val_loss: 2.0490 - val_accuracy: 0.4000\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.8571 - val_loss: 2.1248 - val_accuracy: 0.4000\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 832us/step - loss: 0.1916 - accuracy: 0.8571 - val_loss: 2.1119 - val_accuracy: 0.4000\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 451us/step - loss: 0.1871 - accuracy: 0.8571 - val_loss: 2.0230 - val_accuracy: 0.4000\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 429us/step - loss: 0.1855 - accuracy: 0.8571 - val_loss: 1.9715 - val_accuracy: 0.4000\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 451us/step - loss: 0.1856 - accuracy: 0.8571 - val_loss: 1.9616 - val_accuracy: 0.4000\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.8571 - val_loss: 2.0164 - val_accuracy: 0.4000\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 565us/step - loss: 0.1829 - accuracy: 0.8571 - val_loss: 2.1263 - val_accuracy: 0.4000\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 525us/step - loss: 0.1790 - accuracy: 0.8571 - val_loss: 2.2444 - val_accuracy: 0.4000\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 834us/step - loss: 0.1754 - accuracy: 0.8571 - val_loss: 2.3694 - val_accuracy: 0.4000\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 663us/step - loss: 0.1720 - accuracy: 0.8571 - val_loss: 2.4902 - val_accuracy: 0.4000\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.8571 - val_loss: 2.6694 - val_accuracy: 0.4000\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 950us/step - loss: 0.1684 - accuracy: 0.8571 - val_loss: 2.8934 - val_accuracy: 0.4000\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 809us/step - loss: 0.1703 - accuracy: 0.8571 - val_loss: 3.0847 - val_accuracy: 0.4000\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 712us/step - loss: 0.1735 - accuracy: 0.8571 - val_loss: 3.2180 - val_accuracy: 0.4000\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.8571 - val_loss: 3.2667 - val_accuracy: 0.4000\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 709us/step - loss: 0.1709 - accuracy: 0.8571 - val_loss: 3.2425 - val_accuracy: 0.4000\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 596us/step - loss: 0.1647 - accuracy: 0.9048 - val_loss: 3.1739 - val_accuracy: 0.4000\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 571us/step - loss: 0.1598 - accuracy: 0.9524 - val_loss: 3.0863 - val_accuracy: 0.4000\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9524 - val_loss: 2.9893 - val_accuracy: 0.4000\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 662us/step - loss: 0.1495 - accuracy: 0.9524 - val_loss: 2.8835 - val_accuracy: 0.4000\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 714us/step - loss: 0.1437 - accuracy: 0.9524 - val_loss: 2.7783 - val_accuracy: 0.4000\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 667us/step - loss: 0.1384 - accuracy: 0.9524 - val_loss: 2.6814 - val_accuracy: 0.4000\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 569us/step - loss: 0.1340 - accuracy: 0.9524 - val_loss: 2.6215 - val_accuracy: 0.4000\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.1297 - accuracy: 0.9524 - val_loss: 2.6294 - val_accuracy: 0.3000\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 427us/step - loss: 0.1253 - accuracy: 0.9524 - val_loss: 2.6992 - val_accuracy: 0.3000\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 617us/step - loss: 0.1200 - accuracy: 0.9524 - val_loss: 2.8195 - val_accuracy: 0.3000\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9524 - val_loss: 2.9675 - val_accuracy: 0.3000\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 901us/step - loss: 0.1065 - accuracy: 0.9524 - val_loss: 3.1391 - val_accuracy: 0.3000\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.0986 - accuracy: 0.9524 - val_loss: 3.2835 - val_accuracy: 0.3000\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 949us/step - loss: 0.0899 - accuracy: 0.9524 - val_loss: 3.0476 - val_accuracy: 0.3000\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 2.4412 - val_accuracy: 0.3000\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 712us/step - loss: 0.0950 - accuracy: 1.0000 - val_loss: 2.1024 - val_accuracy: 0.2000\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 856us/step - loss: 0.1153 - accuracy: 0.9524 - val_loss: 2.6819 - val_accuracy: 0.3000\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 617us/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 3.8493 - val_accuracy: 0.3000\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 427us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 4.6662 - val_accuracy: 0.4000\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 437us/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 5.2085 - val_accuracy: 0.4000\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 427us/step - loss: 0.0829 - accuracy: 0.9524 - val_loss: 5.5070 - val_accuracy: 0.4000\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 428us/step - loss: 0.0881 - accuracy: 0.9524 - val_loss: 5.6015 - val_accuracy: 0.4000\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 665us/step - loss: 0.0744 - accuracy: 0.9524 - val_loss: 5.5779 - val_accuracy: 0.4000\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 773us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 5.5087 - val_accuracy: 0.3000\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 5.4358 - val_accuracy: 0.3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 453us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 5.3038 - val_accuracy: 0.3000\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 548us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 5.1205 - val_accuracy: 0.3000\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 5.0424 - val_accuracy: 0.3000\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 807us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 5.1754 - val_accuracy: 0.3000\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 619us/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 5.5275 - val_accuracy: 0.3000\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 6.0124 - val_accuracy: 0.3000\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 801us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 6.5248 - val_accuracy: 0.3000\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 902us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 6.9214 - val_accuracy: 0.3000\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 7.2789 - val_accuracy: 0.3000\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 7.5937 - val_accuracy: 0.3000\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 7.9258 - val_accuracy: 0.3000\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 527us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 8.1053 - val_accuracy: 0.3000\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 562us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.2524 - val_accuracy: 0.3000\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 622us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 8.3399 - val_accuracy: 0.3000\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 855us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 8.3925 - val_accuracy: 0.3000\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 569us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 8.4214 - val_accuracy: 0.3000\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 667us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 8.4533 - val_accuracy: 0.3000\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 902us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 8.4711 - val_accuracy: 0.3000\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 8.4848 - val_accuracy: 0.3000\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 902us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 8.4877 - val_accuracy: 0.3000\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 617us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.4778 - val_accuracy: 0.3000\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 807us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.4491 - val_accuracy: 0.3000\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 978us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 8.3727 - val_accuracy: 0.3000\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 758us/step - loss: 8.2447e-04 - accuracy: 1.0000 - val_loss: 8.2850 - val_accuracy: 0.3000\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 7.1194e-04 - accuracy: 1.0000 - val_loss: 8.2065 - val_accuracy: 0.3000\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 807us/step - loss: 6.4589e-04 - accuracy: 1.0000 - val_loss: 8.0921 - val_accuracy: 0.3000\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 682us/step - loss: 6.0749e-04 - accuracy: 1.0000 - val_loss: 8.0723 - val_accuracy: 0.3000\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 665us/step - loss: 5.8593e-04 - accuracy: 1.0000 - val_loss: 8.0254 - val_accuracy: 0.3000\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 5.7256e-04 - accuracy: 1.0000 - val_loss: 7.9739 - val_accuracy: 0.3000\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 568us/step - loss: 5.6202e-04 - accuracy: 1.0000 - val_loss: 7.9842 - val_accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history=model.fit(feature_scaled,label_categorical, epochs=200, batch_size=20, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDIKSI MODEL\n",
    "Prediksi model diambil dari nilai pada data X yang telah di preprocessing, dimana nantinya nilai prediksi tersebut digunakan sebagai parameter confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "rounded = [round(feature [0] ) for feature in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=model.history.history['loss']\n",
    "acc=model.history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict= model.predict(feature_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 1.8477440e-05, 7.9900306e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.7680581e-01],\n",
       "       [0.0000000e+00, 2.5928020e-06, 8.5662508e-01],\n",
       "       [0.0000000e+00, 9.2387199e-07, 9.3046248e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.8910999e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.9760824e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.9631053e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.9172843e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.6385413e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.8304343e-01],\n",
       "       [5.0783157e-05, 7.4938524e-01, 7.1811676e-04],\n",
       "       [0.0000000e+00, 3.7941337e-04, 3.7202626e-01],\n",
       "       [1.4901161e-07, 2.9415786e-03, 3.8268733e-01],\n",
       "       [1.1086464e-05, 7.6461726e-01, 2.5182962e-04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.6893585e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.7770977e-01],\n",
       "       [0.0000000e+00, 1.4305115e-06, 9.0424085e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.8824406e-01],\n",
       "       [4.2134523e-04, 6.7875373e-01, 4.0748715e-03],\n",
       "       [0.0000000e+00, 5.9604645e-08, 9.5687479e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.9472535e-01],\n",
       "       [0.0000000e+00, 1.4889240e-04, 1.1150959e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.7256529e-01],\n",
       "       [0.0000000e+00, 2.3841858e-07, 9.2635024e-01],\n",
       "       [1.4007092e-06, 1.8778890e-02, 1.0900399e-01],\n",
       "       [0.0000000e+00, 7.7992678e-05, 7.1047395e-01],\n",
       "       [0.0000000e+00, 6.7532063e-05, 7.7679724e-02],\n",
       "       [1.7881393e-07, 1.9152987e-01, 5.1024556e-04],\n",
       "       [0.0000000e+00, 1.5318394e-05, 7.1756709e-01],\n",
       "       [0.0000000e+00, 1.0132790e-06, 9.0900272e-01],\n",
       "       [5.9604645e-08, 1.5920132e-02, 2.4785725e-02]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 161us/step\n",
      "77.4193525314331\n"
     ]
    }
   ],
   "source": [
    "acc= model.evaluate(feature_scaled,label_categorical)\n",
    "print(acc[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(label_categorical.argmax(axis=1),predict.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance\n",
    "Setelah mendapatkan hasil singkat dari proses training pada model diatas, selanjutnya dapat dilakukan analisis performance dengan membuat confusion matrix dari Y yang telah diubah menjadi categorical dan nilai prediksi dari model neural network terhadap X yang telah di preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Konversi Array Confusion Matrix Kedalam Variabel Bertipe Float\n",
    "Karena data yang didapat dari confusion matrix masih dalam bentuk array, untuk dapat mengkalkulasi nilai tersebut haruslah mengkonversinya kebentuk tipe data integer ataupun float Disini menggunakan tipe data float yangdapat menampilkan nilai berkoma yang nantinya akan membuat persentase dari akurasi, sensitivity, specivicity, dan presisi lebih akurat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  6],\n",
       "       [ 1, 21]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[[0],[0]]\n",
    "TP = float (TP)\n",
    "\n",
    "FP = cm[[0],[1]]\n",
    "FP = float (FP)\n",
    "\n",
    "FN = cm[[1],[0]]\n",
    "FN = float (FN)\n",
    "\n",
    "TN = cm[[1],[1]]\n",
    "TN = float  (TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Accuracy\n",
    "Akurasi dalam masalah klasifikasi adalah jumlah prediksi yang tepat yang dibuat oleh model atas semua jenis prediksi yang dibuat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.41935483870968 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', ((TP+TN)/(TP+TN+FP+FN)) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Precision\n",
    "Presisi adalah ukuran yang memberi tahu berapa proporsi pasien yang didiagnosis menderita kanker yang sebenarnya memang menderita kanker. Yang diprediksi mengidap kanker (TP dan FP) dan orang-orang yang benar-benar mengidap kanker (TP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 33.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "print('Precision:', (TP/(TP+FP) * 100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Sensitivity\n",
    "Sensitivity adalah ukuran yang memberitahu berapa proporsi pasien yang benar-benar menderita kanker didiagnosis oleh algoritmik sebagai kanker. Yang sebenarnya mengidap kanker (TP dan FN) dan orang-orang yang didiagnosis oleh model yang mengidap kanker (TP). (Catatan: FN dimasukkan karena Orang itu benar-benar mengidap kanker meskipun modelnya memperkirakan sebaliknya)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 75.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Sensitivity:', (TP/(TP+FN) * 100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Specificity\n",
    "Spesifitas adalah ukuran yang memberitahu berapa proporsi pasien yang TIDAK menderita kanker, diprediksi oleh model sebagai non-kanker. Yang sebenarnya tidak mengidap kanker(FP dan TN) dan orang-orang yang didiagnosis oleh model tidak menderita kanker adalah TN. (Catatan: FP disertakan karena Orang itu TIDAK benar-benar menderita kanker meskipun modelnya memperkirakan sebaliknya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 77.77777777777779 %\n"
     ]
    }
   ],
   "source": [
    "print('Specificity:', (TN/(TN+FP) * 100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisasi Proses Training\n",
    "Dari proses training diatas, setiap loss pada epochs yang terjadi ketika training dapat ditampilkan dalam bentuk grafik. setiap komponen pada grafik pun dapat ditentukan sesuai keperluan masing-masing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL AKURASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
