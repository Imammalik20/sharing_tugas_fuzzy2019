{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"\">\n",
    "<center><br><font size=\"12\"><font face=\"calibri\"><strong>Tugas UAS \n",
    "    <br>\n",
    "<br><strong>Mata Kuliah Kecerdasan Buatan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kanker payudara adalah kondisi ketika sel kanker terbentuk di jaringan payudara. Kanker bisa terbentuk di kelenjar yang menghasilkan susu (lobulus), atau di saluran (duktus) yang membawa air susu dari kelenjar ke puting payudara. Kanker juga bisa terbentuk di jaringan lemak atau jaringan ikat di dalam payudara.Di seluruh dunia, kanker payudara adalah jenis kanker yang paling umum pada wanita dan tertinggi kedua dalam hal tingkat kematian. Diagnosis kanker payudara dilakukan ketika benjolan abnormal ditemukan (dari pemeriksaan sendiri atau x-ray) atau setitik kecil dari kalsium terlihat (pada x-ray). Setelah benjolan yang mencurigakan ditemukan, dokter akan melakukan diagnosis untuk menentukan apakah itu adalah kanker dan, jika demikian, apakah telah menyebar ke bagian lain dari tubuh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini Saya menggunakan DataSet Breast Cancer Winconsin(Prognostic) Yang saya dapat dari website database yang bernama KAGGLE\n",
    "Adapun Linknya : https://www.kaggle.com/sarahvch/breast-cancer-wisconsin-prognostic-data-set\n",
    "\n",
    "Pada Dataset ini terdapat 569 data dan 31 Variabel Yang Terdiri dari :\n",
    "1. radius_mean                    \n",
    "2. texture_mean\n",
    "3. perimeter_mean\n",
    "4. area_mean\n",
    "5. smoothness_mean\n",
    "6. compactness_mean\n",
    "7. concavity_mean\n",
    "8. concave points_mean\n",
    "9. symmetry_mean\n",
    "10. fractal_dimension_mean\n",
    "11. radius_se\n",
    "12. texture_se\n",
    "13. perimeter_se\n",
    "14. area_se\n",
    "15. smoothness_se\n",
    "16. compactness_se\n",
    "17. concavity_se\n",
    "18. concave points_se\n",
    "19. symmetry_se\n",
    "20. fractal_dimension_se\n",
    "21. radius_worst\n",
    "22. texture_worst\n",
    "23. perimeter_worst\n",
    "24. area_worst\n",
    "25. smoothness_worst\n",
    "26. compactness_worst\n",
    "27. concavity_worst\n",
    "28. concave points_worst\n",
    "29. symmetry_worst\n",
    "30. fractal_dimension_worst\n",
    "31. Diagnosis\n",
    "    - 0 = B Atau Tidak terdiagnosis Kanker payudara\n",
    "    - 1 = M Terdeteksi Kanker payudara\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network (ANN)\n",
    "\n",
    "- ANN adalah salah satu main tools yang digunakan dalam Machine Learning\n",
    "- Seperti yang ditunjukkan oleh bagian \"Neural\" dari namanya, mereka adalah sistem \"Brain-Inspired\" yang dimaksudkan untuk mereplikasi cara  manusia belajar.\n",
    "- Neural Network terdiri dari input dan output layer, serta (dalam kebanyakan kasus) hidden layer yang terdiri dari unit-unit yang mengubah input menjadi sesuatu yang dapat digunakan oleh output layer.\n",
    "- ANN adalah tools yang sangat baik untuk menemukan pola yang terlalu rumit atau banyak bagi seorang programmer untuk mengekstraksi dan mengajarkan mesin untuk mengenali sesuatu.\n",
    "- Neural Network juga disebut \"perceptrons\".\n",
    "- Neural Network telah menjadi bagian utama dari kecerdasan buatan dalam beberapa dekade terakhir. Ini disebabkan oleh kedatangan teknik yang disebut \"backpropagation,\" yang memungkinkan network untuk menyesuaikan hidden layer neuron mereka dalam situasi di mana hasilnya tidak sesuai dengan apa yang diharapkan creator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Memanggil Library yang diperlukan ,\n",
    "from sklearn.preprocessing import MinMaxScaler #\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.activations import relu\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/RAFI/Downloads/Prof/dataset/data 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Unnamed: 32','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada Bagian ini,saya mengubah isi diagnosis yang sebelumnya adalah M dan B dengan mengubahnya menjadi 1 dan 0,karna dalam pemosresan bahasa python,bahasa ini tidak dapat memporses kalimat dan hanya bisa memproses numerical,dalam pengubahan ini saya menggunakan proses Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>455</td>\n",
       "      <td>452</td>\n",
       "      <td>444</td>\n",
       "      <td>531</td>\n",
       "      <td>521</td>\n",
       "      <td>526</td>\n",
       "      <td>416</td>\n",
       "      <td>...</td>\n",
       "      <td>425</td>\n",
       "      <td>41</td>\n",
       "      <td>497</td>\n",
       "      <td>516</td>\n",
       "      <td>358</td>\n",
       "      <td>516</td>\n",
       "      <td>520</td>\n",
       "      <td>483</td>\n",
       "      <td>485</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>426</td>\n",
       "      <td>186</td>\n",
       "      <td>486</td>\n",
       "      <td>513</td>\n",
       "      <td>120</td>\n",
       "      <td>215</td>\n",
       "      <td>321</td>\n",
       "      <td>396</td>\n",
       "      <td>219</td>\n",
       "      <td>...</td>\n",
       "      <td>419</td>\n",
       "      <td>199</td>\n",
       "      <td>465</td>\n",
       "      <td>511</td>\n",
       "      <td>158</td>\n",
       "      <td>210</td>\n",
       "      <td>278</td>\n",
       "      <td>401</td>\n",
       "      <td>222</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>406</td>\n",
       "      <td>324</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>403</td>\n",
       "      <td>459</td>\n",
       "      <td>478</td>\n",
       "      <td>516</td>\n",
       "      <td>348</td>\n",
       "      <td>...</td>\n",
       "      <td>399</td>\n",
       "      <td>261</td>\n",
       "      <td>455</td>\n",
       "      <td>491</td>\n",
       "      <td>287</td>\n",
       "      <td>464</td>\n",
       "      <td>438</td>\n",
       "      <td>468</td>\n",
       "      <td>445</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>297</td>\n",
       "      <td>164</td>\n",
       "      <td>95</td>\n",
       "      <td>471</td>\n",
       "      <td>533</td>\n",
       "      <td>507</td>\n",
       "      <td>493</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>298</td>\n",
       "      <td>281</td>\n",
       "      <td>194</td>\n",
       "      <td>408</td>\n",
       "      <td>524</td>\n",
       "      <td>511</td>\n",
       "      <td>479</td>\n",
       "      <td>499</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>418</td>\n",
       "      <td>60</td>\n",
       "      <td>493</td>\n",
       "      <td>506</td>\n",
       "      <td>332</td>\n",
       "      <td>414</td>\n",
       "      <td>480</td>\n",
       "      <td>492</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>381</td>\n",
       "      <td>28</td>\n",
       "      <td>453</td>\n",
       "      <td>470</td>\n",
       "      <td>239</td>\n",
       "      <td>245</td>\n",
       "      <td>415</td>\n",
       "      <td>363</td>\n",
       "      <td>81</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1          370             1             455        452   \n",
       "1          1          426           186             486        513   \n",
       "2          1          406           324             478        487   \n",
       "3          1           98           297             164         95   \n",
       "4          1          418            60             493        506   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0              444               531             521                  526   \n",
       "1              120               215             321                  396   \n",
       "2              403               459             478                  516   \n",
       "3              471               533             507                  493   \n",
       "4              332               414             480                  492   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0            416  ...           425             41              497   \n",
       "1            219  ...           419            199              465   \n",
       "2            348  ...           399            261              455   \n",
       "3            426  ...           215            298              281   \n",
       "4            216  ...           381             28              453   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0         516               358                516              520   \n",
       "1         511               158                210              278   \n",
       "2         491               287                464              438   \n",
       "3         194               408                524              511   \n",
       "4         470               239                245              415   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                   483             485                      506  \n",
       "1                   401             222                      375  \n",
       "2                   468             445                      361  \n",
       "3                   479             499                      533  \n",
       "4                   363              81                      216  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "dataset = data.apply(enc.fit_transform)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bisa kita lihat setelah di ubah,pada isi Label Diagnosis sudah berubah Menjadi 1 dan 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing\n",
    "\n",
    "Preprocessing data adalah tahap penting dalam pembelajaran mesin, karena data masukan yang baik dan tepat (harusnya) akan membuat estimator mampu menghasilkan keluaran yang baik pula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada Bagian ini,kita melakukan proses membagi data menjadi 2 kategori,yang pertama adalah X yang berisi Fitur dan Y yang berupa Label,disini label nya adalah \"Diagnosis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,1:33].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membagi Data train dan test\n",
    "\n",
    "Model Machine Learning,biasanya membutuhkan Data Train Dan data Test,hal yang harus di perhatikan adalah,sebaiknya proposi data Train harus lebih banyak dari data test,seperti dalam hal ini saya membagi data Train sebanyak 80% dan data Test Sebanyak 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data train test.\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitur Normalisasi\n",
    "\n",
    "Normalisasi adalah konsep penting lainnya yang diperlukan untuk mengubah semua fitur ke skala yang sama. Hal ini memungkinkan konvergensi yang lebih cepat pada pembelajaran, dan pengaruh yang lebih seragam untuk semua bobot. Dalam hal ini digunakan MinMaxScaler yang mengubah fitur dengan penskalaan setiap fitur ke rentang yang diberikan (menjadi antara 0 dan 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55604396, 0.94142259, 0.60652591, ..., 0.51836735, 0.09292929,\n",
       "        0.60412758],\n",
       "       [0.17362637, 0.29079498, 0.15547025, ..., 0.08571429, 0.17171717,\n",
       "        0.24015009],\n",
       "       [0.86813187, 0.78242678, 0.89635317, ..., 0.76122449, 0.74747475,\n",
       "        0.75797373],\n",
       "       ...,\n",
       "       [0.35164835, 0.03974895, 0.35508637, ..., 0.03673469, 0.10909091,\n",
       "        0.2195122 ],\n",
       "       [0.33626374, 0.02719665, 0.35892514, ..., 0.53061224, 0.70505051,\n",
       "        0.36210131],\n",
       "       [0.79120879, 0.87029289, 0.83685221, ..., 0.76734694, 0.05858586,\n",
       "        0.77110694]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.54285714,  0.06694561,  0.5950096 , ...,  0.50204082,\n",
       "         0.05858586,  0.28517824],\n",
       "       [ 0.64395604,  0.51464435,  0.69097889, ...,  0.67959184,\n",
       "         0.59393939,  0.62476548],\n",
       "       [ 0.07032967,  0.41841004,  0.05758157, ...,  0.03061224,\n",
       "         0.66262626,  0.4727955 ],\n",
       "       ...,\n",
       "       [ 0.74945055,  0.69037657,  0.80038388, ...,  0.89387755,\n",
       "         0.89494949,  0.79737336],\n",
       "       [ 0.64835165,  0.89748954,  0.66410749, ...,  0.04693878,\n",
       "        -0.0040404 , -0.00187617],\n",
       "       [ 0.76483516,  0.5125523 ,  0.81957774, ...,  0.97346939,\n",
       "         0.7030303 ,  0.72232645]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Sequential\n",
    "\n",
    "Model Sekuensial adalah tumpukan lapisan linear. Dalam menentukan bentuk masukan, model perlu tahu bentuk masukan apa yang diharapkan. Lapisan pertama dalam model Sequential (dan hanya yang pertama, karena lapisan berikutnya dapat melakukan inferensi bentuk otomatis) perlu menerima informasi tentang bentuk inputnya. Kemudian untuk menambahkan lapisan cukup dengan menambahkan perintah add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units =200 ,input_dim = 30,activation=\"relu\"))\n",
    "model.add(Dense(units =150 ,activation=\"relu\"))\n",
    "model.add(Dense(units =1 ,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di mode sequential ini,Saya menggunakan 3 layer yang terdiri dari :\n",
    "1. Input Layer dan Hidden Layer 1\n",
    "2. Hidden Layer 2\n",
    "3. Output Layer\n",
    "\n",
    "Terdapat Input_dim,input Dim adalah Banyak nya Fitur Yang Kita gunakan,disini saya menggunakan 30 fitur\n",
    "\n",
    "#### Activation Function\n",
    "\n",
    "**Activation** function befungsi untuk menentukan apakah neuron tersebut harus “aktif” atau tidak berdasarkan dari weighted sum dari input. Secara umum terdapat 2 jenis activation function, Linear dan Non-Linear Activation function.\n",
    "disini saya menggunakan Activation Function ReLu Untuk Input\n",
    "\n",
    "**Relu** melakukan “treshold” dari 0 hingga infinity. ReLU juga dapat menutupi kelemahan yang dimiliki oleh Sigmoid. Karna ReLU pada intinya hanya membuat pembatas pada bilangan nol, artinya apabila x ≤ 0 maka x = 0 dan apabila x > 0 maka x = x Ada beberapa pro dan kontra ketika kita menggunakan ReLU:\n",
    "\n",
    "Kelebihan :\n",
    "\n",
    "   - ReLU sangat mempercepat proses konvergensi yang dilakukan dengan stochastic gradient descent jika dibandingkan dengan sigmoid / tanh.\n",
    "    Jika kita bandingan dengan sigmoid/tanh yang memiliki operasi-operasi yang “expensive” (exponentials, etc.), ReLU bisa kita implementasikan hanya dengan membuat pembatas(threshold) pada bilangan nol.\n",
    "\n",
    "Kekurangan :\n",
    "\n",
    "   - Sayangnya, unit ReLU bisa menjadi rapuh pada saat proses training dan bisa membuat unit tersebut “mati”. Sebagai contohnya, kita mungkin bisa menemukan bahwa 40% dari network kita “mati” (neuron yang tidak akan pernah aktif selama proses training) apabila learning rate yang kita inisialisasi terlalu tinggi. Namun apabila kita menginisialisasi learning rate kita secara tepat maka hal seperti ini jarang menjadi masalah.\n",
    "   \n",
    "**Untuk Output saya menggunakan Activation Sigmoid**\n",
    "\n",
    "**Sigmoid** function mempunyai rentang antara 0 hingga 1 sedangkan rentang dari Tanh adalah -1 hingga 1.\n",
    "Sigmoid memiliki bentuk formula sebagai berikut :\n",
    "\\begin{split}S(x) = \\frac{1} { 1+e-x }\\end{split}\n",
    "Sigmoid akan menerima angka tunggal dan mengubah nilai x menjadi sebuah nilai yang memiliki range mulai dari 0 sampai 1. Belakangan ini Sigmoid tidak disukai dan jarang digunakan, sigmoid memiliki kekurangan berupa:\n",
    "- Sigmoid mematikan gradient, property yang paling tidak diinginkan dari Sigmoid adalah ketika activation dari neuron mengeluarkan nilai yang berada pada ekor 0 atau 1, dimana gradient di wilayah ini hampir nol. Karena itu, jika gradient memiliki nilai yang sangat kecil, Sigmoid akan “mematikan” gradient dan kita sangat tidak menginginkan hal ini terjadi saat melakukan backpropagation.\n",
    "- Output dari Sigmoid tidak zero-centered. Hal ini berimplikasi pada kedinamisan saat melakukan gradient descent, karna apabila data yang datang ke neuron selalu positif maka gradient pada weights selama backpropagation akan menjadi semua positif atau semua negatif. Hal seperti ini dapat mengganggu proses training, tetapi hal ini tidak separah seperti hal yang ada pada point pertama(mematikan gradient).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(lr=0.00001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini Saya menggunakan Optimizer Adam dengan learning rate 0.00001\n",
    "\n",
    "## dibawah ini adalah pengertian dari Optimizer dan Adam\n",
    "\n",
    "Adapun Pengertian Optimizer adalah \n",
    "- digunakan untuk memperbarui bobot dan bias yaitu parameter internal model untuk mengurangi kesalahan.\n",
    "  Teknik yang paling penting dan dasar bagaimana kita melatih dan mengoptimalkan model kita adalah menggunakan   Gradient Descent.digunakan untuk memperbarui bobot dan bias yaitu parameter internal model untuk mengurangi kesalahan.\n",
    "  Teknik yang paling penting dan dasar bagaimana kita melatih dan mengoptimalkan model kita adalah menggunakan Gradient Descent.\n",
    "  \n",
    "\n",
    "**Adam** merupakan cara lain untuk menggunakan gradien masa sebelumnya untuk menghitung gradien saat ini. Adam juga memanfaatkan konsep momentum dengan menambahkan pecahan dari gradien sebelumnya ke yang sekarang. Pengoptimal ini telah menjadi sangat luas, dan secara praktis diterima untuk digunakan dalam test neural network.\n",
    "\n",
    "Disini saya juga menggunakan loss **Binary_crossentropy**,saya menggunakan loss tersebut karna,pada label yang akan kita cari isi nya berupa bilangan biner atau 0 dan 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 0.7076 - accuracy: 0.5714 - val_loss: 0.7112 - val_accuracy: 0.5263\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.7037 - accuracy: 0.5714 - val_loss: 0.7066 - val_accuracy: 0.5263\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.7000 - accuracy: 0.5824 - val_loss: 0.7024 - val_accuracy: 0.5175\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.6962 - accuracy: 0.5780 - val_loss: 0.6982 - val_accuracy: 0.5351\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.6926 - accuracy: 0.5670 - val_loss: 0.6937 - val_accuracy: 0.5351\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.6889 - accuracy: 0.5890 - val_loss: 0.6898 - val_accuracy: 0.5351\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.6855 - accuracy: 0.5934 - val_loss: 0.6857 - val_accuracy: 0.5439\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.6821 - accuracy: 0.6132 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.6787 - accuracy: 0.6286 - val_loss: 0.6782 - val_accuracy: 0.5702\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.6754 - accuracy: 0.6418 - val_loss: 0.6741 - val_accuracy: 0.6053\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.6718 - accuracy: 0.6593 - val_loss: 0.6701 - val_accuracy: 0.6316\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.6684 - accuracy: 0.6857 - val_loss: 0.6662 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.6650 - accuracy: 0.6989 - val_loss: 0.6626 - val_accuracy: 0.6754\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.6618 - accuracy: 0.7055 - val_loss: 0.6591 - val_accuracy: 0.6754\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.6585 - accuracy: 0.7209 - val_loss: 0.6556 - val_accuracy: 0.7018\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.6552 - accuracy: 0.7407 - val_loss: 0.6516 - val_accuracy: 0.7193\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.6518 - accuracy: 0.7429 - val_loss: 0.6479 - val_accuracy: 0.7544\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.6485 - accuracy: 0.7582 - val_loss: 0.6442 - val_accuracy: 0.7632\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.6452 - accuracy: 0.7626 - val_loss: 0.6405 - val_accuracy: 0.7719\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.6419 - accuracy: 0.7626 - val_loss: 0.6369 - val_accuracy: 0.7719\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 0.6388 - accuracy: 0.7692 - val_loss: 0.6332 - val_accuracy: 0.7807\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.6355 - accuracy: 0.7714 - val_loss: 0.6295 - val_accuracy: 0.7807\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.6322 - accuracy: 0.7736 - val_loss: 0.6257 - val_accuracy: 0.7895\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.6288 - accuracy: 0.7758 - val_loss: 0.6218 - val_accuracy: 0.8158\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 0.6254 - accuracy: 0.7890 - val_loss: 0.6182 - val_accuracy: 0.8158\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.6222 - accuracy: 0.7956 - val_loss: 0.6144 - val_accuracy: 0.8158\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 0.6187 - accuracy: 0.8000 - val_loss: 0.6106 - val_accuracy: 0.8246\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.6154 - accuracy: 0.8044 - val_loss: 0.6068 - val_accuracy: 0.8246\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.6120 - accuracy: 0.8154 - val_loss: 0.6030 - val_accuracy: 0.8246\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 0.6086 - accuracy: 0.8132 - val_loss: 0.5993 - val_accuracy: 0.8246\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.6053 - accuracy: 0.8176 - val_loss: 0.5956 - val_accuracy: 0.8246\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.6018 - accuracy: 0.8176 - val_loss: 0.5919 - val_accuracy: 0.8246\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.5985 - accuracy: 0.8198 - val_loss: 0.5881 - val_accuracy: 0.8246\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.5951 - accuracy: 0.8242 - val_loss: 0.5846 - val_accuracy: 0.8246\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.5918 - accuracy: 0.8286 - val_loss: 0.5810 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.5885 - accuracy: 0.8330 - val_loss: 0.5775 - val_accuracy: 0.8421\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.5852 - accuracy: 0.8330 - val_loss: 0.5737 - val_accuracy: 0.8421\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.5818 - accuracy: 0.8330 - val_loss: 0.5701 - val_accuracy: 0.8421\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.5785 - accuracy: 0.8330 - val_loss: 0.5667 - val_accuracy: 0.8421\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 0.5751 - accuracy: 0.8352 - val_loss: 0.5631 - val_accuracy: 0.8421\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.5718 - accuracy: 0.8352 - val_loss: 0.5595 - val_accuracy: 0.8421\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.5684 - accuracy: 0.8352 - val_loss: 0.5560 - val_accuracy: 0.8421\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.5652 - accuracy: 0.8374 - val_loss: 0.5525 - val_accuracy: 0.8509\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.5620 - accuracy: 0.8374 - val_loss: 0.5491 - val_accuracy: 0.8509\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.5589 - accuracy: 0.8374 - val_loss: 0.5458 - val_accuracy: 0.8421\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.5556 - accuracy: 0.8396 - val_loss: 0.5424 - val_accuracy: 0.8509\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.5525 - accuracy: 0.8418 - val_loss: 0.5389 - val_accuracy: 0.8509\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.5493 - accuracy: 0.8462 - val_loss: 0.5355 - val_accuracy: 0.8509\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.5461 - accuracy: 0.8462 - val_loss: 0.5320 - val_accuracy: 0.8509\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.5428 - accuracy: 0.8462 - val_loss: 0.5286 - val_accuracy: 0.8509\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 0.5396 - accuracy: 0.8505 - val_loss: 0.5251 - val_accuracy: 0.8596\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.5364 - accuracy: 0.8527 - val_loss: 0.5218 - val_accuracy: 0.8684\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.5332 - accuracy: 0.8571 - val_loss: 0.5183 - val_accuracy: 0.8684\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.5299 - accuracy: 0.8593 - val_loss: 0.5149 - val_accuracy: 0.8684\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.5267 - accuracy: 0.8615 - val_loss: 0.5115 - val_accuracy: 0.8684\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.5235 - accuracy: 0.8571 - val_loss: 0.5083 - val_accuracy: 0.8509\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 0.5204 - accuracy: 0.8637 - val_loss: 0.5050 - val_accuracy: 0.8684\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.5173 - accuracy: 0.8637 - val_loss: 0.5018 - val_accuracy: 0.8684\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.5142 - accuracy: 0.8615 - val_loss: 0.4987 - val_accuracy: 0.8596\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.5112 - accuracy: 0.8571 - val_loss: 0.4957 - val_accuracy: 0.8509\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.5082 - accuracy: 0.8571 - val_loss: 0.4927 - val_accuracy: 0.8596\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.5052 - accuracy: 0.8571 - val_loss: 0.4896 - val_accuracy: 0.8596\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 0.5023 - accuracy: 0.8571 - val_loss: 0.4867 - val_accuracy: 0.8509\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 0.4993 - accuracy: 0.8571 - val_loss: 0.4835 - val_accuracy: 0.8596\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.4964 - accuracy: 0.8571 - val_loss: 0.4805 - val_accuracy: 0.8596\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.4935 - accuracy: 0.8571 - val_loss: 0.4775 - val_accuracy: 0.8596\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.4906 - accuracy: 0.8615 - val_loss: 0.4743 - val_accuracy: 0.8596\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 160us/step - loss: 0.4877 - accuracy: 0.8637 - val_loss: 0.4714 - val_accuracy: 0.8596\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.4849 - accuracy: 0.8637 - val_loss: 0.4685 - val_accuracy: 0.8596\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.4820 - accuracy: 0.8637 - val_loss: 0.4658 - val_accuracy: 0.8596\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.4794 - accuracy: 0.8659 - val_loss: 0.4629 - val_accuracy: 0.8596\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.4766 - accuracy: 0.8637 - val_loss: 0.4602 - val_accuracy: 0.8596\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.4739 - accuracy: 0.8659 - val_loss: 0.4575 - val_accuracy: 0.8596\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.4713 - accuracy: 0.8659 - val_loss: 0.4547 - val_accuracy: 0.8596\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.4685 - accuracy: 0.8681 - val_loss: 0.4520 - val_accuracy: 0.8596\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.4660 - accuracy: 0.8703 - val_loss: 0.4494 - val_accuracy: 0.8596\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.4635 - accuracy: 0.8681 - val_loss: 0.4468 - val_accuracy: 0.8596\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 0.4610 - accuracy: 0.8703 - val_loss: 0.4443 - val_accuracy: 0.8596\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.4584 - accuracy: 0.8703 - val_loss: 0.4418 - val_accuracy: 0.8596\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.4557 - accuracy: 0.8703 - val_loss: 0.4393 - val_accuracy: 0.8596\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.4533 - accuracy: 0.8703 - val_loss: 0.4368 - val_accuracy: 0.8684\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.4509 - accuracy: 0.8725 - val_loss: 0.4343 - val_accuracy: 0.8596\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.4484 - accuracy: 0.8725 - val_loss: 0.4319 - val_accuracy: 0.8684\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.4459 - accuracy: 0.8769 - val_loss: 0.4295 - val_accuracy: 0.8596\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.4435 - accuracy: 0.8769 - val_loss: 0.4271 - val_accuracy: 0.8684\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.4411 - accuracy: 0.8747 - val_loss: 0.4246 - val_accuracy: 0.8684\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.4386 - accuracy: 0.8747 - val_loss: 0.4222 - val_accuracy: 0.8684\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 0.4363 - accuracy: 0.8747 - val_loss: 0.4199 - val_accuracy: 0.8684\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 0.4340 - accuracy: 0.8725 - val_loss: 0.4177 - val_accuracy: 0.8772\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 0.4316 - accuracy: 0.8769 - val_loss: 0.4154 - val_accuracy: 0.8772\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 0.4293 - accuracy: 0.8769 - val_loss: 0.4131 - val_accuracy: 0.8860\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 0.4270 - accuracy: 0.8791 - val_loss: 0.4108 - val_accuracy: 0.8860\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 0.4247 - accuracy: 0.8791 - val_loss: 0.4085 - val_accuracy: 0.8860\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.4224 - accuracy: 0.8769 - val_loss: 0.4062 - val_accuracy: 0.8860\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.4201 - accuracy: 0.8769 - val_loss: 0.4040 - val_accuracy: 0.8860\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 0.4179 - accuracy: 0.8747 - val_loss: 0.4018 - val_accuracy: 0.8860\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 0.4156 - accuracy: 0.8769 - val_loss: 0.3996 - val_accuracy: 0.8860\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 154us/step - loss: 0.4133 - accuracy: 0.8769 - val_loss: 0.3974 - val_accuracy: 0.8947\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 0.4111 - accuracy: 0.8725 - val_loss: 0.3952 - val_accuracy: 0.8947\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 0.4090 - accuracy: 0.8769 - val_loss: 0.3932 - val_accuracy: 0.8947\n"
     ]
    }
   ],
   "source": [
    "hasil_train = model.fit(x_train,y_train, validation_data=(x_test,y_test),batch_size=25,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada saat Mau men Train data,saya menggunakan yang namanya **batch_size** dan **Epoch**\n",
    "### Batch Size\n",
    "Batch Size adalah jumlah sampel data yang disebarkan ke Neural Network. Contoh: jika kita mempunyai 100 dataset dan batch size kita adalah 5 maka algoritma ini akan menggunakan 5 sempel data pertama dari 100 data yang kita miliki (ke1, ke2, ke3, ke4, dan ke5) lalu disebarkankan atau ditraining oleh Neural Network sampai selesai kemudian mengambil kembali 5 sampel data kedua dari 100 data (ke6, ke7, ke8, ke9, dan ke10), dan begitu seterusnya sampai 5 sampel data ke 20 (100⁄5=20).\n",
    "\n",
    "### Epoch\n",
    "Epoch adalah proses pengulangan yang terjadi pada saat kita melakukan training data,banyak nya epoch adalah banyaknya pengulangan yang akan kita lakukan,seperti disini saya memakai 100 epoch berarti saya mengulang proses itu sebanyak 100 kali\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HASIL AKHIR AKURASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 79us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39315876260138394, 0.8947368264198303]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_testing  = model.evaluate(x_test, y_test) \n",
    "acc_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi data Testing = 89.47%\n"
     ]
    }
   ],
   "source": [
    "print(\"Akurasi data Testing = %.2f%%\" % (acc_testing[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Model Akurasi Dan Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hasil_train.history['accuracy'])\n",
    "plt.plot(hasil_train.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('Akurasi')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Data training', 'Data Testing'], loc='upper left')\n",
    "plt.savefig('model akurasi1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hasil_train.history['loss'])\n",
    "plt.plot(hasil_train.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Data training', 'Data Testing'], loc='upper left')\n",
    "plt.savefig('model loss1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conflusion Matrix\n",
    "\n",
    "Confusion matrix merupakan salah satu metode yang dapat digunakan untuk mengukur kinerja suatu metode klasifikasi. Pada dasarnya confusion matrix mengandung informasi yang membandingkan hasil klasifikasi yang dilakukan oleh sistem dengan hasil klasifikasi yang seharusnya \n",
    "\n",
    "Menghitung **Confusion Matrix** dapat memberi ide yang lebih baik tentang apakah model klasifikasinya benar dan jenis kesalahan apa yang dibuatnya.\n",
    "\n",
    "- True Positive (TP), yaitu jumlah dari kelas 1 yang benar dan diklasifikasikan sebagai kelas 1.\n",
    "- True Negative (TN), yaitu jumlah dari kelas 0 yang benar diklasifikasikan sebagai kelas 0.\n",
    "- False Positive (FP), yaitu jumlah dari kelas 0 yang salah diklasifikasikan sebagai kelas 1.\n",
    "- False Negative (FN), yaitu jumlah dari kelas 1 yang salah diklasifikasikan sebagai kelas 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INport Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "prediction = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction\n",
    "\n",
    "y_test_number = np.argmax(prediction,axis=1) #ubah one hot encoding ke data asli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_number = prediction.reshape(114,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm = confusion_matrix(y_test,y_test_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60,  9],\n",
       "       [ 3, 42]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91        69\n",
      "           1       0.82      0.93      0.87        45\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dalam Conflusion Matrix,kita dapat mencari akurasi,spesifikasi,sensitivitas,presisi dengan memakai rumus manual dibawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test 0.8947368421052632\n",
      "Specificity test 0.9333333333333333\n",
      "Sensitivity test 0.8695652173913043\n",
      "Precision test 0.9523809523809523\n",
      "F1 Score test 0.909090909090909\n"
     ]
    }
   ],
   "source": [
    "tp = test_cm[0][0]\n",
    "fn = test_cm[0][1]\n",
    "fp = test_cm[1][0]\n",
    "tn = test_cm[1][1]\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f1_score = (2*sensitivity*precision)/(sensitivity+precision)\n",
    "\n",
    "print(\"Accuracy test {0}\".format(accuracy))\n",
    "print(\"Specificity test {0}\".format(specificity))\n",
    "print(\"Sensitivity test {0}\".format(sensitivity))\n",
    "print(\"Precision test {0}\".format(precision))\n",
    "print(\"F1 Score test {0}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
